{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch.optim.lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "style.use('seaborn')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from create_translate_data import create_dateset, truncate_pad\n",
    "from util import *\n",
    "from attention import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs):\n",
    "        super(PositionWiseFFN, self).__init__()\n",
    "        self.layer1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.layer2(self.relu(self.layer1(X)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, shape, dropout, use_bias=False):\n",
    "        super(AddNorm, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(shape)\n",
    "        self.use_bias = use_bias\n",
    "        if self.use_bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(shape))\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        if self.use_bias:\n",
    "            return self.layer_norm(X + Y + self.bias)\n",
    "        else:\n",
    "            return self.layer_norm(X + self.dropout(Y))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class AddNorm_no_ln(nn.Module):\n",
    "    def __init__(self, shape, dropout, use_bias=False):\n",
    "        super(AddNorm_no_ln, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(shape)\n",
    "        self.use_bias = use_bias\n",
    "        if self.use_bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(shape))\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        if self.use_bias:\n",
    "            return X + Y + self.bias\n",
    "        else:\n",
    "            return X + self.dropout(Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, dropout, use_bias=False):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout, use_bias)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout, use_bias)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))\n",
    "\n",
    "# X = torch.ones((2, 100, 24))\n",
    "# valid_lens = torch.tensor([3, 2])\n",
    "# encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
    "# encoder_blk.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class EncoderBlock_no_ln(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, dropout, use_bias=False):\n",
    "        super(EncoderBlock_no_ln, self).__init__()\n",
    "        self.attention = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm_no_ln(norm_shape, dropout, use_bias)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm_no_ln(norm_shape, dropout, use_bias)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))\n",
    "\n",
    "# X = torch.ones((2, 100, 24))\n",
    "# valid_lens = torch.tensor([3, 2])\n",
    "# encoder_blk = EncoderBlock_no_ln(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
    "# encoder_blk.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout, use_bias=False):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"encoder_blk_%d\" % i, EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                                                                    norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                                                                    num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        for blk in self.blks:\n",
    "            X = blk(X, valid_lens)\n",
    "        return X\n",
    "\n",
    "\n",
    "# encoder = TransformerEncoder(\n",
    "#     200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
    "# encoder.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class TransformerEncoder_no_ln(nn.Module):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout, use_bias=False):\n",
    "        super(TransformerEncoder_no_ln, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"encoder_blk_%d\" % i, EncoderBlock_no_ln(key_size, query_size, value_size, num_hiddens,\n",
    "                                                                    norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                                                                    num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        for blk in self.blks:\n",
    "            X = blk(X, valid_lens)\n",
    "        return X\n",
    "\n",
    "\n",
    "# encoder = TransformerEncoder(\n",
    "#     200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
    "# encoder.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, dropout, i, use_bias=False):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout, use_bias)\n",
    "        self.attention2 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout, use_bias)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout, use_bias)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "\n",
    "        batch_size, num_steps, _ = X.shape\n",
    "        dec_valid_lens = torch.arange(\n",
    "            1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "\n",
    "        X2 = self.attention1(X, X, X, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class DecoderBlock_no_ln(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, dropout, i, use_bias=False):\n",
    "        super(DecoderBlock_no_ln, self).__init__()\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm_no_ln(norm_shape, dropout, use_bias)\n",
    "        self.attention2 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm_no_ln(norm_shape, dropout, use_bias)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm3 = AddNorm_no_ln(norm_shape, dropout, use_bias)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "\n",
    "        batch_size, num_steps, _ = X.shape\n",
    "        dec_valid_lens = torch.arange(\n",
    "            1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "\n",
    "        X2 = self.attention1(X, X, X, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout, use_bias=False):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"decoder_blk_%d\" % i, DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                                                                    norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                                                                    num_heads, dropout, i, use_bias))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        self.seqX = None\n",
    "        return [enc_outputs, enc_valid_lens]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        if not self.training:\n",
    "            self.seqX = X if self.seqX is None else torch.cat((self.seqX, X), dim=1)\n",
    "            X = self.seqX\n",
    "\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            self._attention_weights[0][\n",
    "                i] = blk.attention1.attention.attention_weights\n",
    "            self._attention_weights[1][\n",
    "                i] = blk.attention2.attention.attention_weights\n",
    "\n",
    "        if not self.training:\n",
    "            return self.dense(X)[:, -1:, :], state\n",
    "\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class TransformerDecoder_no_ln(nn.Module):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout, use_bias=False):\n",
    "        super(TransformerDecoder_no_ln, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"decoder_blk_%d\" % i, DecoderBlock_no_ln(key_size, query_size, value_size, num_hiddens,\n",
    "                                                                    norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                                                                    num_heads, dropout, i, use_bias))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        self.seqX = None\n",
    "        return [enc_outputs, enc_valid_lens]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        if not self.training:\n",
    "            self.seqX = X if self.seqX is None else torch.cat((self.seqX, X), dim=1)\n",
    "            X = self.seqX\n",
    "\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            self._attention_weights[0][\n",
    "                i] = blk.attention1.attention.attention_weights\n",
    "            self._attention_weights[1][\n",
    "                i] = blk.attention2.attention.attention_weights\n",
    "\n",
    "        if not self.training:\n",
    "            return self.dense(X)[:, -1:, :], state\n",
    "\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, enc_valid_lens):\n",
    "        enc_outputs = self.encoder(enc_X, enc_valid_lens)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, enc_valid_lens)\n",
    "        return self.decoder(dec_X, dec_state)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 60\n",
    "num_epochs = 1000\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "corpus_size = 1000\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [num_hiddens]\n",
    "en_file = 'en-de/train.en-de.low.filt.en'\n",
    "de_file = 'en-de/train.en-de.low.filt.de'\n",
    "data_iter, input_vocab, target_vocab = create_dateset(en_file, de_file, corpus_size, 2, 10, device, batch_size)\n",
    "loss = MaskedSoftmaxCELoss()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "acc_test_input = []\n",
    "test_files_input = open(en_file, 'r', encoding='UTF-8')\n",
    "line = test_files_input.readline().strip().split()\n",
    "acc_test_input.append(' '.join(line[:20]))\n",
    "for i in range(99):\n",
    "    line = test_files_input.readline().strip().split()\n",
    "    if len(line) > 20:\n",
    "        acc_test_input.append(' '.join(line[:20]))\n",
    "    else:\n",
    "        acc_test_input.append(' '.join(line))\n",
    "test_files_input.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[\"with vibrant video clips captured by submarines , david gallo takes us to some of earth 's darkest , most\",\n \"david gallo : this is bill lange . i 'm dave gallo .\",\n \"and we 're going to tell you some stories from the sea here in video .\",\n \"we 've got some of the most incredible video of titanic that 's ever been seen , and we 're\",\n \"the truth of the matter is that the titanic -- even though it 's breaking all sorts of box office\",\n 'and the problem , i think , is that we take the ocean for granted .',\n 'when you think about it , the oceans are 75 percent of the planet .',\n 'most of the planet is ocean water .',\n 'the average depth is about two miles .',\n 'part of the problem , i think , is we stand at the beach , or we see images like',\n 'and in the oceans , there are the longest mountain ranges on the planet .',\n 'most of the animals are in the oceans .',\n 'most of the earthquakes and volcanoes are in the sea , at the bottom of the sea .',\n 'the biodiversity and the biodensity in the ocean is higher , in places , than it is in the rainforests',\n \"it 's mostly unexplored , and yet there are beautiful sights like this that captivate us and make us become\",\n \"but when you 're standing at the beach , i want you to think that you 're standing at the\",\n 'we have to have a very special technology to get into that unfamiliar world .',\n 'we use the submarine alvin and we use cameras , and the cameras are something that bill lange has developed',\n 'marcel proust said , `` the true voyage of discovery is not so much in seeking new landscapes as in',\n 'people that have partnered with us have given us new eyes , not only on what exists -- the new',\n \"here 's a jelly .\",\n \"it 's one of my favorites , because it 's got all sorts of working parts .\",\n 'this turns out to be the longest creature in the oceans .',\n 'it gets up to about 150 feet long .',\n 'but see all those different working things ?',\n 'i love that kind of stuff .',\n \"it 's got these fishing lures on the bottom . they 're going up and down .\",\n \"it 's got tentacles dangling , swirling around like that .\",\n \"it 's a colonial animal .\",\n 'these are all individual animals banding together to make this one creature .',\n \"and it 's got these jet thrusters up in front that it 'll use in a moment , and a\",\n 'if you take all the big fish and schooling fish and all that , put them on one side of',\n 'most of the biomass in the ocean is made out of creatures like this .',\n \"here 's the x-wing death jelly .\",\n 'the bioluminescence -- they use the lights for attracting mates and attracting prey and communicating .',\n \"we could n't begin to show you our archival stuff from the jellies .\",\n 'they come in all different sizes and shapes .',\n 'bill lange : we tend to forget about the fact that the ocean is miles deep on average , and',\n 'and these are the types of animals that live in that three-dimensional space , that micro-gravity environment that we really',\n 'you hear about giant squid and things like that , but some of these animals get up to be approximately',\n \"they 're very little understood .\",\n \"dg : this is one of them , another one of our favorites , because it 's a little octopod\",\n 'you can actually see through his head .',\n 'and here he is , flapping with his ears and very gracefully going up .',\n 'we see those at all depths and even at the greatest depths .',\n 'they go from a couple of inches to a couple of feet .',\n \"they come right up to the submarine -- they 'll put their eyes right up to the window and peek\",\n \"this is really a world within a world , and we 're going to show you two .\",\n \"in this case , we 're passing down through the mid-ocean and we see creatures like this .\",\n 'this is kind of like an undersea rooster .',\n 'this guy , that looks incredibly formal , in a way .',\n 'and then one of my favorites . what a face !',\n \"this is basically scientific data that you 're looking at .\",\n \"it 's footage that we 've collected for scientific purposes .\",\n \"and that 's one of the things that bill 's been doing , is providing scientists with this first view\",\n \"they do n't catch them in a net .\",\n \"they 're actually looking at them down in that world .\",\n \"we 're going to take a joystick , sit in front of our computer , on the earth , and\",\n \"we 're going to look at the mid-ocean ridge , a 40,000-mile long mountain range .\",\n 'the average depth at the top of it is about a mile and a half .',\n \"and we 're over the atlantic -- that 's the ridge right there -- but we 're going to go\",\n 'we make maps of these mountain ranges with sound , with sonar , and this is one of those mountain',\n \"we 're coming around a cliff here on the right .\",\n 'the height of these mountains on either side of this valley is greater than the alps in most cases .',\n \"and there 's tens of thousands of those mountains out there that have n't been mapped yet .\",\n 'this is a volcanic ridge .',\n \"we 're getting down further and further in scale .\",\n 'and eventually , we can come up with something like this .',\n \"this is an icon of our robot , jason , it 's called .\",\n 'and you can sit in a room like this , with a joystick and a headset , and drive a',\n \"one of the things we 're trying to do at woods hole with our partners is to bring this virtual\",\n 'because we see it in bits and pieces right now .',\n 'we see it either as sound , or we see it as video , or we see it as photographs',\n \"here 's where bill 's cameras really do shine .\",\n \"this is what 's called a hydrothermal vent .\",\n \"and what you 're seeing here is a cloud of densely packed , hydrogen-sulfide-rich water coming out of a volcanic\",\n 'gets up to 600 , 700 degrees f , somewhere in that range .',\n \"so that 's all water under the sea -- a mile and a half , two miles , three miles\",\n \"and we knew it was volcanic back in the '60s , '70s .\",\n 'and then we had some hint that these things existed all along the axis of it , because if you',\n \"we were n't really aware that it would be so rich with sulfides , hydrogen sulfides .\",\n \"we did n't have any idea about these things , which we call chimneys .\",\n 'this is one of these hydrothermal vents .',\n 'six hundred degree f water coming out of the earth .',\n 'on either side of us are mountain ranges that are higher than the alps , so the setting here is',\n 'bl : the white material is a type of bacteria that thrives at 180 degrees c .',\n \"dg : i think that 's one of the greatest stories right now that we 're seeing from the bottom\",\n 'and we started to wonder for a long time , how did it all get down there ?',\n \"what we find out now is that it 's probably coming from inside the earth .\",\n 'not only is it coming out of the earth -- so , biogenesis made from volcanic activity -- but that',\n 'the pressure here is 4,000 pounds per square inch .',\n 'a mile and a half from the surface to two miles to three miles -- no sun has ever gotten',\n 'all the energy to support these life forms is coming from inside the earth -- so , chemosynthesis .',\n 'and you can see how dense the population is .',\n 'these are called tube worms .',\n 'bl : these worms have no digestive system . they have no mouth .',\n 'but they have two types of gill structures .',\n 'one for extracting oxygen out of the deep-sea water , another one which houses this chemosynthetic bacteria , which takes',\n \"dg : you can see , here 's a crab that lives down there .\",\n \"he 's managed to grab a tip of these worms .\"]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test_input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "acc_test_target = []\n",
    "test_files_target = open(de_file, 'r', encoding='UTF-8')\n",
    "line = test_files_target.readline().strip().split()\n",
    "acc_test_target.append(line[:20])\n",
    "for i in range(99):\n",
    "    line = test_files_target.readline().strip().split()\n",
    "    if len(line) > 20:\n",
    "        acc_test_target.append(line[:20])\n",
    "    else:\n",
    "        acc_test_target.append(line)\n",
    "test_files_target.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[['mit',\n  'hilfe',\n  'von',\n  'lebendigen',\n  'videos',\n  ',',\n  'die',\n  'von',\n  'unterseebooten',\n  'gemacht',\n  'wurden',\n  ',',\n  'führt',\n  'uns',\n  'david',\n  'gallo',\n  'zu',\n  'den',\n  'dunkelsten',\n  ','],\n ['david',\n  'gallo',\n  ':',\n  'das',\n  'ist',\n  'bill',\n  'lange',\n  '.',\n  'ich',\n  'bin',\n  'dave',\n  'gallo',\n  '.'],\n ['wir',\n  'werden',\n  'ihnen',\n  'einige',\n  'geschichten',\n  'über',\n  'das',\n  'meer',\n  'in',\n  'videoform',\n  'erzählen',\n  '.'],\n ['wir',\n  'haben',\n  'ein',\n  'paar',\n  'der',\n  'unglaublichsten',\n  'aufnahmen',\n  'der',\n  'titanic',\n  ',',\n  'die',\n  'man',\n  'je',\n  'gesehen',\n  'hat',\n  ',',\n  ',',\n  'und',\n  'wir',\n  'werden'],\n ['die',\n  'wahrheit',\n  'ist',\n  ',',\n  'dass',\n  'die',\n  'titanic',\n  '–',\n  'obwohl',\n  'sie',\n  'alle',\n  'kinokassenrekorde',\n  'bricht',\n  '–',\n  'nicht',\n  'gerade',\n  'die',\n  'aufregendste',\n  'geschichte',\n  'vom'],\n ['ich',\n  'denke',\n  ',',\n  'das',\n  'problem',\n  'ist',\n  ',',\n  'dass',\n  'wir',\n  'das',\n  'meer',\n  'für',\n  'zu',\n  'selbstverständlich',\n  'halten',\n  '.'],\n ['wenn',\n  'man',\n  'darüber',\n  'nachdenkt',\n  ',',\n  'machen',\n  'die',\n  'ozeane',\n  '75',\n  '%',\n  'des',\n  'planeten',\n  'aus',\n  '.'],\n ['der', 'großteil', 'der', 'erde', 'ist', 'meerwasser', '.'],\n ['die', 'durchschnittliche', 'tiefe', 'ist', 'etwa', '3', 'kilometer', '.'],\n ['ein',\n  'teil',\n  'des',\n  'problems',\n  'ist',\n  ',',\n  'dass',\n  'wir',\n  'am',\n  'strand',\n  'stehen',\n  'oder',\n  'bilder',\n  'wie',\n  'dieses',\n  'hier',\n  'sehen',\n  'und',\n  'auf',\n  'die'],\n ['in',\n  'den',\n  'ozeanen',\n  'befinden',\n  'sich',\n  'die',\n  'längsten',\n  'gebirgszüge',\n  'des',\n  'planeten',\n  '.'],\n ['die', 'meisten', 'tiere', 'leben', 'in', 'den', 'ozeanen', '.'],\n ['der',\n  'großteil',\n  'der',\n  'erdbeben',\n  'und',\n  'vulkanausbrüche',\n  'spielt',\n  'sich',\n  'im',\n  'meer',\n  'ab',\n  '–',\n  'am',\n  'meeresboden',\n  '.'],\n ['an',\n  'einigen',\n  'stellen',\n  'ist',\n  'die',\n  'vielfalt',\n  'und',\n  'die',\n  'dichte',\n  'des',\n  'lebens',\n  'im',\n  'ozean',\n  'höher',\n  'als',\n  'in',\n  'den',\n  'regenwäldern',\n  '.'],\n ['das',\n  'meiste',\n  'ist',\n  'unerforscht',\n  ',',\n  'und',\n  'doch',\n  'gibt',\n  'es',\n  'schönheiten',\n  'wie',\n  'diese',\n  ',',\n  'die',\n  'uns',\n  'fesseln',\n  'und',\n  'uns',\n  'vertrauter',\n  'mit'],\n ['aber',\n  'wenn',\n  'sie',\n  'am',\n  'strand',\n  'stehen',\n  ',',\n  'möchte',\n  'ich',\n  ',',\n  'dass',\n  'sie',\n  'sich',\n  'vorstellen',\n  ',',\n  'an',\n  'der',\n  'grenze',\n  'zu',\n  'einer'],\n ['wir',\n  'müssen',\n  'uns',\n  'schon',\n  'einer',\n  'sehr',\n  'speziellen',\n  'technik',\n  'bedienen',\n  ',',\n  'um',\n  'in',\n  'diese',\n  'unbekannte',\n  'welt',\n  'vorzudringen',\n  '.'],\n ['wir',\n  'benutzen',\n  'das',\n  'unterseeboot',\n  'alvin',\n  'und',\n  'kameras',\n  ',',\n  'und',\n  'diese',\n  'kameras',\n  'hat',\n  'bill',\n  'lange',\n  'mit',\n  'hilfe',\n  'von',\n  'sony',\n  'entwickelt',\n  '.'],\n ['marcel',\n  'proust',\n  'hat',\n  'einmal',\n  'gesagt',\n  ':',\n  '``',\n  'die',\n  'wahre',\n  'entdeckungsreise',\n  'besteht',\n  'nicht',\n  'darin',\n  ',',\n  'dass',\n  'man',\n  'neue',\n  'länder',\n  'sucht',\n  ','],\n ['die',\n  'menschen',\n  ',',\n  'die',\n  'mit',\n  'uns',\n  'zusammengearbeitet',\n  'haben',\n  ',',\n  'gaben',\n  'uns',\n  'neue',\n  'augen',\n  ',',\n  'nicht',\n  'nur',\n  ',',\n  'um',\n  'das',\n  'zu'],\n ['das', 'ist', 'ein', 'weichtier', '.'],\n ['es',\n  'ist',\n  'einer',\n  'meiner',\n  'lieblinge',\n  ',',\n  'weil',\n  'es',\n  'alle',\n  'möglichen',\n  'funktionsteile',\n  'hat',\n  '.'],\n ['es',\n  'hat',\n  'sich',\n  'als',\n  'das',\n  'längste',\n  'wesen',\n  'im',\n  'meer',\n  'erwiesen',\n  '.'],\n ['es', 'wird', 'bis', 'zu', '50', 'meter', 'lang', '.'],\n ['sehen', 'sie', 'all', 'die', 'unterschiedlichen', 'teile', '?'],\n ['so', 'was', 'mag', 'ich', '.'],\n ['es',\n  'hat',\n  'diese',\n  'fischköder',\n  'an',\n  'der',\n  'unterseite',\n  '.',\n  'die',\n  'bewegen',\n  'sich',\n  'auf',\n  'und',\n  'ab',\n  '.'],\n ['es', 'hat', 'tentakel', ',', 'die', 'so', 'herumschwirren', '.'],\n ['es', 'ist', 'eine', 'kolonie', 'von', 'tieren', '.'],\n ['das',\n  'sind',\n  'alles',\n  'einzelne',\n  'lebewesen',\n  ',',\n  'die',\n  'sich',\n  'zu',\n  'diesem',\n  'einen',\n  'organismus',\n  'zusammenschließen',\n  '.'],\n ['es',\n  'hat',\n  'vorne',\n  'diese',\n  'antriebsdüsen',\n  ',',\n  'die',\n  'es',\n  'gleich',\n  'benutzt',\n  ',',\n  'und',\n  'ein',\n  'kleines',\n  'licht',\n  '.'],\n ['wenn',\n  'man',\n  'alle',\n  'großen',\n  'fische',\n  'und',\n  'fischschulen',\n  'und',\n  'all',\n  'das',\n  'nimmt',\n  'und',\n  'auf',\n  'die',\n  'eine',\n  'seite',\n  'der',\n  'waage',\n  'legt',\n  'und'],\n ['der',\n  'großteil',\n  'der',\n  'biomasse',\n  'im',\n  'meer',\n  'besteht',\n  'aus',\n  'geschöpfen',\n  'wie',\n  'diesem',\n  '.'],\n ['hier', 'ist', 'das', 'x-wing-todes-weichtier', '.'],\n ['sie',\n  'benutzen',\n  'die',\n  'biolumineszenz',\n  ',',\n  'um',\n  'geschlechtspartner',\n  'anzulocken',\n  ',',\n  'beute',\n  'zu',\n  'ködern',\n  'und',\n  'zur',\n  'verständigung',\n  '.'],\n ['wir',\n  'hätten',\n  'niemals',\n  'die',\n  'zeit',\n  ',',\n  'ihnen',\n  'all',\n  'unser',\n  'archivmaterial',\n  'von',\n  'den',\n  'weichtieren',\n  'zu',\n  'zeigen',\n  '.'],\n ['es',\n  'gibt',\n  'sie',\n  'in',\n  'den',\n  'unterschiedlichsten',\n  'größen',\n  'und',\n  'formen',\n  '.'],\n ['bill',\n  'lange',\n  ':',\n  'wir',\n  'vergessen',\n  'leicht',\n  ',',\n  'dass',\n  'das',\n  'meer',\n  'durchschnittlich',\n  'mehrere',\n  'kilometer',\n  'tief',\n  'ist',\n  'und',\n  'dass',\n  'wir',\n  'nur',\n  'die'],\n ['diese',\n  'tierarten',\n  'leben',\n  'in',\n  'einem',\n  'dreidimensionalen',\n  'raum',\n  ',',\n  'einem',\n  'mikrogravitationsraum',\n  ',',\n  'den',\n  'wir',\n  'überhaupt',\n  'noch',\n  'nicht',\n  'erforscht',\n  'haben',\n  '.'],\n ['man',\n  'hört',\n  'von',\n  'riesenkalmaren',\n  'und',\n  'so',\n  'etwas',\n  ',',\n  'aber',\n  'einige',\n  'dieser',\n  'tiere',\n  'werden',\n  'bis',\n  'zu',\n  'etwa',\n  '50',\n  'meter',\n  'lang',\n  '.'],\n ['man', 'weiß', 'sehr', 'wenig', 'über', 'sie', '.'],\n ['dg',\n  ':',\n  'das',\n  'ist',\n  'eines',\n  'von',\n  'ihnen',\n  ',',\n  'noch',\n  'einer',\n  'unserer',\n  'lieblinge',\n  ',',\n  'denn',\n  'es',\n  'ist',\n  'ein',\n  'kleiner',\n  'oktopus',\n  '.'],\n ['man', 'kann', 'ihm', 'tatsächlich', 'durch', 'den', 'kopf', 'gucken', '.'],\n ['und',\n  'hier',\n  'wackelt',\n  'er',\n  'mit',\n  'den',\n  'ohren',\n  'und',\n  'steigt',\n  'sehr',\n  'anmutig',\n  'nach',\n  'oben',\n  '.'],\n ['wir',\n  'finden',\n  'sie',\n  'in',\n  'allen',\n  'tiefen',\n  'und',\n  'sogar',\n  'in',\n  'die',\n  'tiefsten',\n  'tiefen',\n  '.'],\n ['sie',\n  'sind',\n  'von',\n  'wenigen',\n  'zentimetern',\n  'bis',\n  'hin',\n  'zu',\n  'ein',\n  'paar',\n  'metern',\n  'lang',\n  '.'],\n ['sie',\n  'kommen',\n  'bis',\n  'ans',\n  'u-boot',\n  'heran',\n  '–',\n  'sie',\n  'kommen',\n  'mit',\n  'den',\n  'augen',\n  'ans',\n  'fenster',\n  'und',\n  'gucken',\n  'ins',\n  'u-boot',\n  '.'],\n ['es',\n  'ist',\n  'eine',\n  'eigene',\n  'welt',\n  'in',\n  'der',\n  'welt',\n  ',',\n  'und',\n  'wir',\n  'werden',\n  'ihnen',\n  'zwei',\n  'zeigen',\n  '.'],\n ['in',\n  'diesem',\n  'fall',\n  'bewegen',\n  'wir',\n  'uns',\n  'durch',\n  'die',\n  'ozeanmitte',\n  'nach',\n  'unten',\n  'und',\n  'sehen',\n  'solche',\n  'kreaturen',\n  '.'],\n ['das', 'hier', 'ist', 'eine', 'art', 'unterwasser-hahn', '.'],\n ['der',\n  'hier',\n  ',',\n  'der',\n  'irgendwie',\n  'unglaublich',\n  'förmlich',\n  'aussieht',\n  '.'],\n ['und',\n  'hier',\n  'ist',\n  'einer',\n  'meiner',\n  'lieblinge',\n  '.',\n  'was',\n  'für',\n  'ein',\n  'gesicht',\n  '!'],\n ['was',\n  'sie',\n  'hier',\n  'sehen',\n  ',',\n  'sind',\n  'im',\n  'grunde',\n  'wissenschaftliche',\n  'daten',\n  '.'],\n ['es',\n  'sind',\n  'aufnahmen',\n  ',',\n  'die',\n  'wir',\n  'zu',\n  'forschungszwecken',\n  'gemacht',\n  'haben',\n  '.'],\n ['das',\n  'ist',\n  'auch',\n  'etwas',\n  ',',\n  'das',\n  'bill',\n  'macht',\n  ',',\n  'wissenschaftler',\n  'mit',\n  'den',\n  'ersten',\n  'bildern',\n  'von',\n  'diesen',\n  'tieren',\n  'zu',\n  'versorgen',\n  ','],\n ['sie', 'fangen', 'sie', 'nicht', 'mit', 'einem', 'netz', '.'],\n ['sie',\n  'sehen',\n  'sie',\n  'sich',\n  'da',\n  'unten',\n  'in',\n  'dieser',\n  'welt',\n  'an',\n  '.'],\n ['wir',\n  'nehmen',\n  'einen',\n  'joystick',\n  ',',\n  'sitzen',\n  'vor',\n  'unserem',\n  'computer',\n  'an',\n  'land',\n  ',',\n  'drücken',\n  'den',\n  'joystick',\n  'nach',\n  'vorn',\n  'und',\n  'fliegen',\n  'um'],\n ['wir',\n  'werden',\n  'uns',\n  'den',\n  'mittelozeanischen',\n  'rücken',\n  'ansehen',\n  ',',\n  'ein',\n  '64.000',\n  'kilometer',\n  'langer',\n  'gebirgszug',\n  '.'],\n ['die',\n  'durchschnittliche',\n  'tiefe',\n  'der',\n  'gipfel',\n  'ist',\n  'etwa',\n  '2,5',\n  'kilometer',\n  '.'],\n ['jetzt',\n  'sind',\n  'wir',\n  'über',\n  'dem',\n  'atlantik',\n  '–',\n  'das',\n  'da',\n  'ist',\n  'der',\n  'rücken',\n  '–',\n  ',',\n  'werden',\n  'die',\n  'karibik',\n  ',',\n  'in',\n  'mittelamerika'],\n ['wir',\n  'erstellen',\n  'karten',\n  'dieser',\n  'gebirgszüge',\n  'mit',\n  'hilfe',\n  'von',\n  'schall',\n  ',',\n  'sonar',\n  ',',\n  'und',\n  'das',\n  'ist',\n  'einer',\n  'dieser',\n  'gebirgszüge',\n  '.'],\n ['wir', 'biegen', 'um', 'eine', 'klippe', 'hier', 'rechts', '.'],\n ['die',\n  'höhe',\n  'dieser',\n  'berge',\n  'auf',\n  'beiden',\n  'seiten',\n  'des',\n  'tals',\n  'ist',\n  'größer',\n  'als',\n  'die',\n  'der',\n  'alpen',\n  'in',\n  'den',\n  'meisten',\n  'fällen',\n  '.'],\n ['und',\n  'es',\n  'gibt',\n  'zehntausende',\n  'von',\n  'bergen',\n  'hier',\n  'draußen',\n  ',',\n  'die',\n  'auf',\n  'keiner',\n  'karte',\n  'verzeichnet',\n  'sind',\n  '.'],\n ['das', 'ist', 'ein', 'vulkanischer', 'rücken', '.'],\n ['wir', 'tauchen', 'immer', 'tiefer', 'und', 'tiefer', '.'],\n ['und',\n  'schließlich',\n  'kommen',\n  'wir',\n  'auf',\n  'so',\n  'etwas',\n  'wie',\n  'das',\n  'hier',\n  '.'],\n ['das',\n  'ist',\n  'ein',\n  'bild',\n  'unseres',\n  'roboters',\n  '–',\n  'er',\n  'heißt',\n  'jason',\n  '.'],\n ['man',\n  'kann',\n  'in',\n  'einem',\n  'raum',\n  'wie',\n  'diesem',\n  'sitzen',\n  ',',\n  'mit',\n  'einem',\n  'joystick',\n  'und',\n  'einem',\n  'headset',\n  'und',\n  'so',\n  'einen',\n  'roboter',\n  'ohne'],\n ['unter',\n  'anderem',\n  'versuchen',\n  'wir',\n  'mit',\n  'unseren',\n  'partnern',\n  'bei',\n  'woods',\n  'hole',\n  ',',\n  'diese',\n  'virtuelle',\n  'welt',\n  '–',\n  'diese',\n  'welt',\n  ',',\n  'dieses',\n  'unerforschte'],\n ['denn', 'wir', 'sehen', 'sie', 'bisher', 'nur', 'stückweise', '.'],\n ['wir',\n  'nehmen',\n  'sie',\n  'entweder',\n  'als',\n  'geräusch',\n  'war',\n  'oder',\n  'als',\n  'video',\n  'oder',\n  'auf',\n  'fotos',\n  'oder',\n  'mit',\n  'hilfe',\n  'von',\n  'chemischen',\n  'sensoren',\n  '–'],\n ['hier', 'brillieren', 'bills', 'kameras', 'richtig', '.'],\n ['das', 'hier', 'nennt', 'man', 'eine', 'hydrothermale', 'quelle', '.'],\n ['und',\n  'hier',\n  'sieht',\n  'man',\n  'eine',\n  'wolke',\n  'von',\n  'dichtem',\n  'hydrogensulfidreichem',\n  'wasser',\n  ',',\n  'das',\n  'aus',\n  'einer',\n  'vulkanischen',\n  'längsachse',\n  'am',\n  'meeresboden',\n  'tritt',\n  '.'],\n ['es', 'wird', 'bis', 'zu', 'etwa', '300', 'grad', 'celsius', 'heiß', '.'],\n ['das',\n  'ist',\n  'also',\n  'alles',\n  'wasser',\n  'unter',\n  'dem',\n  'meer',\n  '–',\n  'zwei',\n  ',',\n  'drei',\n  ',',\n  'vier',\n  'kilometer',\n  'in',\n  'der',\n  'tiefe',\n  '.'],\n ['wir',\n  'wussten',\n  'bereits',\n  'in',\n  'den',\n  '60ern',\n  'und',\n  '70ern',\n  ',',\n  'dass',\n  'es',\n  'vulkanisch',\n  'ist',\n  '.'],\n ['damit',\n  'hatten',\n  'wir',\n  'einen',\n  'hinweis',\n  ',',\n  'dass',\n  'es',\n  'diese',\n  'quellen',\n  'entlang',\n  'dieser',\n  'achse',\n  'gibt',\n  ',',\n  'denn',\n  'wenn',\n  'es',\n  'vulkanismus',\n  'gibt'],\n ['uns',\n  'war',\n  'nicht',\n  'bewusst',\n  ',',\n  'dass',\n  'es',\n  'so',\n  'reich',\n  'an',\n  'hydrogensulfiden',\n  'ist',\n  '.'],\n ['wir',\n  'hatten',\n  'keine',\n  'ahnung',\n  'von',\n  'diesen',\n  'dingern',\n  ',',\n  'die',\n  'wir',\n  'schornsteine',\n  'nennen',\n  '.'],\n ['das', 'ist', 'eine', 'dieser', 'hydrothermalen', 'quellen', '.'],\n ['300', 'grad', 'heißes', 'wasser', 'tritt', 'aus', 'der', 'erde', '.'],\n ['auf',\n  'beiden',\n  'seiten',\n  'liegen',\n  'gebirgszüge',\n  ',',\n  'die',\n  'höher',\n  'als',\n  'die',\n  'alpen',\n  'sind',\n  ',',\n  'diese',\n  'gegend',\n  'hier',\n  'ist',\n  'also',\n  'sehr',\n  'dramatisch'],\n ['bl',\n  ':',\n  'das',\n  'weiße',\n  'ist',\n  'eine',\n  'bakterienart',\n  ',',\n  'die',\n  'bei',\n  '180',\n  'grad',\n  'celsius',\n  'gedeiht',\n  '.'],\n ['dg',\n  ':',\n  'ich',\n  'finde',\n  ',',\n  'eine',\n  'der',\n  'größten',\n  'geschichten',\n  ',',\n  'die',\n  'wir',\n  'gerade',\n  'auf',\n  'dem',\n  'meeresgrund',\n  'entdecken',\n  ',',\n  'ist',\n  ','],\n ['lange',\n  'haben',\n  'wir',\n  'uns',\n  'gefragt',\n  ':',\n  'wie',\n  'sind',\n  'die',\n  'alle',\n  'da',\n  'unten',\n  'hingekommen',\n  '?'],\n ['inzwischen',\n  'haben',\n  'wir',\n  'herausgefunden',\n  ',',\n  'dass',\n  'sie',\n  'wahrscheinlich',\n  'aus',\n  'dem',\n  'erdinneren',\n  'gekommen',\n  'sind',\n  '.'],\n ['sie',\n  'kommen',\n  'nicht',\n  'nur',\n  'aus',\n  'der',\n  'erde',\n  '–',\n  'vom',\n  'vulkanismus',\n  'angestoßene',\n  'biogenese',\n  '–',\n  'bakterien',\n  'unterstützen',\n  'auch',\n  'diese',\n  'kolonien',\n  'des',\n  'lebens'],\n ['der',\n  'druck',\n  'beträgt',\n  'hier',\n  '800',\n  'kg',\n  'pro',\n  'quadratzentimeter',\n  '.'],\n ['2,5',\n  'bis',\n  '3',\n  'oder',\n  '5',\n  'kilometer',\n  'unter',\n  'der',\n  'oberfläche',\n  '–',\n  'kein',\n  'sonnenstrahl',\n  'ist',\n  'jemals',\n  'bis',\n  'hierher',\n  'vorgedrungen',\n  '.'],\n ['die',\n  'ganze',\n  'energie',\n  ',',\n  'die',\n  'diese',\n  'lebewesen',\n  'antreibt',\n  ',',\n  'kommt',\n  'aus',\n  'dem',\n  'erdinneren',\n  '–',\n  'chemosynthese',\n  'also',\n  '.'],\n ['und',\n  'sie',\n  'sehen',\n  ',',\n  'wie',\n  'dicht',\n  'das',\n  'leben',\n  'hier',\n  'ist',\n  '.'],\n ['das', 'hier', 'sind', 'röhrenwürmer', '.'],\n ['bl',\n  ':',\n  'diese',\n  'würmer',\n  'haben',\n  'kein',\n  'verdauungssystem',\n  '.',\n  'sie',\n  'haben',\n  'keinen',\n  'mund',\n  '.'],\n ['aber', 'sie', 'haben', 'zwei', 'arten', 'von', 'kiemenstrukturen', '.'],\n ['eine',\n  'für',\n  'das',\n  'aufnehmen',\n  'von',\n  'sauerstoff',\n  'aus',\n  'dem',\n  'meerwasser',\n  'und',\n  'die',\n  'andere',\n  'beherbergt',\n  'diese',\n  'chemosynthetischen',\n  'bakterien',\n  ',',\n  'die',\n  'die',\n  'hydrothermale'],\n ['dg',\n  ':',\n  'sie',\n  'können',\n  'sehen',\n  '–',\n  'hier',\n  'ist',\n  'eine',\n  'krabbe',\n  ',',\n  'die',\n  'dort',\n  'unten',\n  'lebt',\n  '.'],\n ['sie',\n  'hat',\n  'ein',\n  'stück',\n  'dieser',\n  'würmer',\n  'zu',\n  'fassen',\n  'gekriegt',\n  '.']]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test_target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=False):\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def predict_seq2seq_beam(net, src_sentence, src_vocab, tgt_vocab, num_steps, device, k=3, save_attention_weights=False):\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    max_prob = -float('inf')\n",
    "    max_output_seq, max_attention_weight_seq = [], []\n",
    "    # beam first step, pick top 3\n",
    "    Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "    top_dec_X = torch.topk(Y, k=k, dim=2)\n",
    "    for i in top_dec_X[0].to(torch.long).permute(2, 0, 1):\n",
    "        curr_prob = i\n",
    "        dec_X = i\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "        for _ in range(1, num_steps):\n",
    "            Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "            dec_X = Y.argmax(dim=2)\n",
    "            pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "            if save_attention_weights:\n",
    "                attention_weight_seq.append(net.decoder.attention_weights)\n",
    "            if pred == tgt_vocab['<eos>']:\n",
    "                break\n",
    "            output_seq.append(pred)\n",
    "        if curr_prob.float() > max_prob:\n",
    "            max_prob = curr_prob\n",
    "            max_output_seq = output_seq\n",
    "            max_attention_weight_seq = attention_weight_seq\n",
    "        output_seq, attention_weight_seq = [], []\n",
    "\n",
    "    return ' '.join(tgt_vocab.to_tokens(max_output_seq)), max_attention_weight_seq"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def train_transformer(model, num_epochs, data_iter, optimizer, scheduler):\n",
    "    best_loss = float('inf')\n",
    "    learning_curve = [np.nan] * (num_epochs//10+1)\n",
    "    bleu_scores = [np.nan] * (num_epochs//10+1)\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(2)\n",
    "        model.train()\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([target_vocab['<bos>']] * Y.shape[0], device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)\n",
    "            Y_hat, _ = model(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            grad_clipping(model, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if epoch == 0:\n",
    "            learning_curve[0] = metric[0] / metric[1]\n",
    "            model.eval()\n",
    "            bleu_scores[0] = 0\n",
    "            for sent in range(len(acc_test_input)):\n",
    "                target_len = len(acc_test_target[sent])\n",
    "                pred, dec_att_wei = predict_seq2seq(model, acc_test_input[sent], input_vocab, target_vocab, target_len, device, True)\n",
    "                bleu_scores[0] += bleu(pred, ' '.join(acc_test_target[sent]), len(pred.split()))\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch+1, num_epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format((metric[0] / metric[1])))\n",
    "            learning_curve[(epoch+1)//10] = metric[0] / metric[1]\n",
    "            model.eval()\n",
    "            bleu_scores[(epoch+1)//10] = 0\n",
    "            for sent in range(len(acc_test_input)):\n",
    "                target_len = len(acc_test_target[sent])\n",
    "                pred, dec_att_wei = predict_seq2seq(model, acc_test_input[sent], input_vocab, target_vocab, target_len, device, True)\n",
    "                bleu_scores[(epoch+1)//10] += bleu(pred, ' '.join(acc_test_target[sent]), len(pred.split()))\n",
    "            print('Epoch: {}/{}.............'.format(epoch+1, num_epochs), end=' ')\n",
    "            print(\"Bleu: {:.4f}\".format(bleu_scores[(epoch+1)//10]))\n",
    "\n",
    "        if (metric[0] / metric[1]) < best_loss:\n",
    "            best_loss = (metric[0] / metric[1])\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_weights, 'transformer_weights_'+str(corpus_size)+'_sentences_' +\n",
    "                       str(num_epochs)+'_epochs.pth')\n",
    "        scheduler.step()\n",
    "\n",
    "    return learning_curve, bleu_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def train_transformer_no_ln(model, num_epochs, data_iter, optimizer, scheduler):\n",
    "    best_loss = float('inf')\n",
    "    learning_curve = [np.nan] * (num_epochs//10+1)\n",
    "    bleu_scores = [np.nan] * (num_epochs//10+1)\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(2)\n",
    "        model.train()\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([target_vocab['<bos>']] * Y.shape[0], device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)\n",
    "            Y_hat, _ = model(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            grad_clipping(model, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if epoch == 0:\n",
    "            learning_curve[0] = metric[0] / metric[1]\n",
    "            model.eval()\n",
    "            bleu_scores[0] = 0\n",
    "            for sent in range(len(acc_test_input)):\n",
    "                target_len = len(acc_test_target[sent])\n",
    "                pred, dec_att_wei = predict_seq2seq(model, acc_test_input[sent], input_vocab, target_vocab, target_len, device, True)\n",
    "                bleu_scores[0] += bleu(pred, ' '.join(acc_test_target[sent]), len(pred.split()))\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch+1, num_epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format((metric[0] / metric[1])))\n",
    "            learning_curve[(epoch+1)//10] = metric[0] / metric[1]\n",
    "            model.eval()\n",
    "            bleu_scores[(epoch+1)//10] = 0\n",
    "            for sent in range(len(acc_test_input)):\n",
    "                target_len = len(acc_test_target[sent])\n",
    "                pred, dec_att_wei = predict_seq2seq(model, acc_test_input[sent], input_vocab, target_vocab, target_len, device, True)\n",
    "                bleu_scores[(epoch+1)//10] += bleu(pred, ' '.join(acc_test_target[sent]), len(pred.split()))\n",
    "            print('Epoch: {}/{}.............'.format(epoch+1, num_epochs), end=' ')\n",
    "            print(\"Bleu: {:.4f}\".format(bleu_scores[(epoch+1)//10]))\n",
    "\n",
    "        if (metric[0] / metric[1]) < best_loss:\n",
    "            best_loss = (metric[0] / metric[1])\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_weights, 'transformer_no_ln_weights_'+str(corpus_size)+'_sentences_' +\n",
    "                       str(num_epochs)+'_epochs.pth')\n",
    "        scheduler.step()\n",
    "\n",
    "    return learning_curve, bleu_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "training_results = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/1000............. Loss: 0.4583\n",
      "Epoch: 10/1000............. Bleu: 0.0000\n",
      "Epoch: 20/1000............. Loss: 0.3853\n",
      "Epoch: 20/1000............. Bleu: 0.0000\n",
      "Epoch: 30/1000............. Loss: 0.3348\n",
      "Epoch: 30/1000............. Bleu: 0.0000\n",
      "Epoch: 40/1000............. Loss: 0.2909\n",
      "Epoch: 40/1000............. Bleu: 0.0000\n",
      "Epoch: 50/1000............. Loss: 0.2626\n",
      "Epoch: 50/1000............. Bleu: 0.0000\n",
      "Epoch: 60/1000............. Loss: 0.2363\n",
      "Epoch: 60/1000............. Bleu: 0.0000\n",
      "Epoch: 70/1000............. Loss: 0.2164\n",
      "Epoch: 70/1000............. Bleu: 0.0000\n",
      "Epoch: 80/1000............. Loss: 0.1990\n",
      "Epoch: 80/1000............. Bleu: 2.0000\n",
      "Epoch: 90/1000............. Loss: 0.1844\n",
      "Epoch: 90/1000............. Bleu: 3.0000\n",
      "Epoch: 100/1000............. Loss: 0.1715\n",
      "Epoch: 100/1000............. Bleu: 4.0000\n",
      "Epoch: 110/1000............. Loss: 0.1622\n",
      "Epoch: 110/1000............. Bleu: 4.0000\n",
      "Epoch: 120/1000............. Loss: 0.1543\n",
      "Epoch: 120/1000............. Bleu: 4.0000\n",
      "Epoch: 130/1000............. Loss: 0.1456\n",
      "Epoch: 130/1000............. Bleu: 4.0000\n",
      "Epoch: 140/1000............. Loss: 0.1376\n",
      "Epoch: 140/1000............. Bleu: 4.0000\n",
      "Epoch: 150/1000............. Loss: 0.1320\n",
      "Epoch: 150/1000............. Bleu: 6.4895\n",
      "Epoch: 160/1000............. Loss: 0.1273\n",
      "Epoch: 160/1000............. Bleu: 6.0000\n",
      "Epoch: 170/1000............. Loss: 0.1214\n",
      "Epoch: 170/1000............. Bleu: 7.4895\n",
      "Epoch: 180/1000............. Loss: 0.1178\n",
      "Epoch: 180/1000............. Bleu: 7.4895\n",
      "Epoch: 190/1000............. Loss: 0.1134\n",
      "Epoch: 190/1000............. Bleu: 5.0000\n",
      "Epoch: 200/1000............. Loss: 0.1092\n",
      "Epoch: 200/1000............. Bleu: 6.4895\n",
      "Epoch: 210/1000............. Loss: 0.1037\n",
      "Epoch: 210/1000............. Bleu: 7.0000\n",
      "Epoch: 220/1000............. Loss: 0.0981\n",
      "Epoch: 220/1000............. Bleu: 7.0000\n",
      "Epoch: 230/1000............. Loss: 0.0965\n",
      "Epoch: 230/1000............. Bleu: 7.0000\n",
      "Epoch: 240/1000............. Loss: 0.0958\n",
      "Epoch: 240/1000............. Bleu: 8.0000\n",
      "Epoch: 250/1000............. Loss: 0.0946\n",
      "Epoch: 250/1000............. Bleu: 6.0000\n",
      "Epoch: 260/1000............. Loss: 0.0926\n",
      "Epoch: 260/1000............. Bleu: 7.4895\n",
      "Epoch: 270/1000............. Loss: 0.0910\n",
      "Epoch: 270/1000............. Bleu: 6.4895\n",
      "Epoch: 280/1000............. Loss: 0.0882\n",
      "Epoch: 280/1000............. Bleu: 8.0000\n",
      "Epoch: 290/1000............. Loss: 0.0888\n",
      "Epoch: 290/1000............. Bleu: 8.0000\n",
      "Epoch: 300/1000............. Loss: 0.0861\n",
      "Epoch: 300/1000............. Bleu: 8.0000\n",
      "Epoch: 310/1000............. Loss: 0.0858\n",
      "Epoch: 310/1000............. Bleu: 8.4895\n",
      "Epoch: 320/1000............. Loss: 0.0820\n",
      "Epoch: 320/1000............. Bleu: 8.4895\n",
      "Epoch: 330/1000............. Loss: 0.0804\n",
      "Epoch: 330/1000............. Bleu: 7.4895\n",
      "Epoch: 340/1000............. Loss: 0.0802\n",
      "Epoch: 340/1000............. Bleu: 8.4895\n",
      "Epoch: 350/1000............. Loss: 0.0802\n",
      "Epoch: 350/1000............. Bleu: 8.4895\n",
      "Epoch: 360/1000............. Loss: 0.0799\n",
      "Epoch: 360/1000............. Bleu: 7.4895\n",
      "Epoch: 370/1000............. Loss: 0.0770\n",
      "Epoch: 370/1000............. Bleu: 8.4895\n",
      "Epoch: 380/1000............. Loss: 0.0767\n",
      "Epoch: 380/1000............. Bleu: 7.4895\n",
      "Epoch: 390/1000............. Loss: 0.0765\n",
      "Epoch: 390/1000............. Bleu: 6.4895\n",
      "Epoch: 400/1000............. Loss: 0.0749\n",
      "Epoch: 400/1000............. Bleu: 6.4895\n",
      "Epoch: 410/1000............. Loss: 0.0699\n",
      "Epoch: 410/1000............. Bleu: 9.4895\n",
      "Epoch: 420/1000............. Loss: 0.0695\n",
      "Epoch: 420/1000............. Bleu: 8.4895\n",
      "Epoch: 430/1000............. Loss: 0.0679\n",
      "Epoch: 430/1000............. Bleu: 7.4895\n",
      "Epoch: 440/1000............. Loss: 0.0681\n",
      "Epoch: 440/1000............. Bleu: 7.4895\n",
      "Epoch: 450/1000............. Loss: 0.0681\n",
      "Epoch: 450/1000............. Bleu: 8.4895\n",
      "Epoch: 460/1000............. Loss: 0.0668\n",
      "Epoch: 460/1000............. Bleu: 8.0000\n",
      "Epoch: 470/1000............. Loss: 0.0668\n",
      "Epoch: 470/1000............. Bleu: 8.4905\n",
      "Epoch: 480/1000............. Loss: 0.0650\n",
      "Epoch: 480/1000............. Bleu: 7.4895\n",
      "Epoch: 490/1000............. Loss: 0.0665\n",
      "Epoch: 490/1000............. Bleu: 8.4895\n",
      "Epoch: 500/1000............. Loss: 0.0641\n",
      "Epoch: 500/1000............. Bleu: 7.4895\n",
      "Epoch: 510/1000............. Loss: 0.0643\n",
      "Epoch: 510/1000............. Bleu: 7.4895\n",
      "Epoch: 520/1000............. Loss: 0.0640\n",
      "Epoch: 520/1000............. Bleu: 7.4895\n",
      "Epoch: 530/1000............. Loss: 0.0635\n",
      "Epoch: 530/1000............. Bleu: 8.4895\n",
      "Epoch: 540/1000............. Loss: 0.0618\n",
      "Epoch: 540/1000............. Bleu: 6.0000\n",
      "Epoch: 550/1000............. Loss: 0.0617\n",
      "Epoch: 550/1000............. Bleu: 8.4905\n",
      "Epoch: 560/1000............. Loss: 0.0620\n",
      "Epoch: 560/1000............. Bleu: 7.4895\n",
      "Epoch: 570/1000............. Loss: 0.0602\n",
      "Epoch: 570/1000............. Bleu: 8.4895\n",
      "Epoch: 580/1000............. Loss: 0.0640\n",
      "Epoch: 580/1000............. Bleu: 7.4895\n",
      "Epoch: 590/1000............. Loss: 0.0618\n",
      "Epoch: 590/1000............. Bleu: 8.4895\n",
      "Epoch: 600/1000............. Loss: 0.0607\n",
      "Epoch: 600/1000............. Bleu: 8.4895\n",
      "Epoch: 610/1000............. Loss: 0.0596\n",
      "Epoch: 610/1000............. Bleu: 7.4895\n",
      "Epoch: 620/1000............. Loss: 0.0586\n",
      "Epoch: 620/1000............. Bleu: 8.4895\n",
      "Epoch: 630/1000............. Loss: 0.0571\n",
      "Epoch: 630/1000............. Bleu: 8.4895\n",
      "Epoch: 640/1000............. Loss: 0.0577\n",
      "Epoch: 640/1000............. Bleu: 8.4895\n",
      "Epoch: 650/1000............. Loss: 0.0562\n",
      "Epoch: 650/1000............. Bleu: 7.4895\n",
      "Epoch: 660/1000............. Loss: 0.0561\n",
      "Epoch: 660/1000............. Bleu: 8.4905\n",
      "Epoch: 670/1000............. Loss: 0.0565\n",
      "Epoch: 670/1000............. Bleu: 7.4895\n",
      "Epoch: 680/1000............. Loss: 0.0565\n",
      "Epoch: 680/1000............. Bleu: 8.4895\n",
      "Epoch: 690/1000............. Loss: 0.0575\n",
      "Epoch: 690/1000............. Bleu: 8.4895\n",
      "Epoch: 700/1000............. Loss: 0.0562\n",
      "Epoch: 700/1000............. Bleu: 8.4895\n",
      "Epoch: 710/1000............. Loss: 0.0549\n",
      "Epoch: 710/1000............. Bleu: 8.4895\n",
      "Epoch: 720/1000............. Loss: 0.0570\n",
      "Epoch: 720/1000............. Bleu: 9.4895\n",
      "Epoch: 730/1000............. Loss: 0.0531\n",
      "Epoch: 730/1000............. Bleu: 9.4895\n",
      "Epoch: 740/1000............. Loss: 0.0577\n",
      "Epoch: 740/1000............. Bleu: 8.4895\n",
      "Epoch: 750/1000............. Loss: 0.0541\n",
      "Epoch: 750/1000............. Bleu: 8.4895\n",
      "Epoch: 760/1000............. Loss: 0.0540\n",
      "Epoch: 760/1000............. Bleu: 8.4895\n",
      "Epoch: 770/1000............. Loss: 0.0538\n",
      "Epoch: 770/1000............. Bleu: 7.4895\n",
      "Epoch: 780/1000............. Loss: 0.0538\n",
      "Epoch: 780/1000............. Bleu: 8.4895\n",
      "Epoch: 790/1000............. Loss: 0.0540\n",
      "Epoch: 790/1000............. Bleu: 7.4895\n",
      "Epoch: 800/1000............. Loss: 0.0540\n",
      "Epoch: 800/1000............. Bleu: 8.4895\n",
      "Epoch: 810/1000............. Loss: 0.0536\n",
      "Epoch: 810/1000............. Bleu: 7.4895\n",
      "Epoch: 820/1000............. Loss: 0.0532\n",
      "Epoch: 820/1000............. Bleu: 8.4895\n",
      "Epoch: 830/1000............. Loss: 0.0526\n",
      "Epoch: 830/1000............. Bleu: 8.4895\n",
      "Epoch: 840/1000............. Loss: 0.0538\n",
      "Epoch: 840/1000............. Bleu: 8.4895\n",
      "Epoch: 850/1000............. Loss: 0.0526\n",
      "Epoch: 850/1000............. Bleu: 8.4895\n",
      "Epoch: 860/1000............. Loss: 0.0512\n",
      "Epoch: 860/1000............. Bleu: 7.4895\n",
      "Epoch: 870/1000............. Loss: 0.0535\n",
      "Epoch: 870/1000............. Bleu: 8.4895\n",
      "Epoch: 880/1000............. Loss: 0.0528\n",
      "Epoch: 880/1000............. Bleu: 6.4895\n",
      "Epoch: 890/1000............. Loss: 0.0517\n",
      "Epoch: 890/1000............. Bleu: 7.4895\n",
      "Epoch: 900/1000............. Loss: 0.0521\n",
      "Epoch: 900/1000............. Bleu: 6.4895\n",
      "Epoch: 910/1000............. Loss: 0.0522\n",
      "Epoch: 910/1000............. Bleu: 6.4895\n",
      "Epoch: 920/1000............. Loss: 0.0508\n",
      "Epoch: 920/1000............. Bleu: 6.4895\n",
      "Epoch: 930/1000............. Loss: 0.0491\n",
      "Epoch: 930/1000............. Bleu: 6.4895\n",
      "Epoch: 940/1000............. Loss: 0.0489\n",
      "Epoch: 940/1000............. Bleu: 7.4895\n",
      "Epoch: 950/1000............. Loss: 0.0496\n",
      "Epoch: 950/1000............. Bleu: 7.4895\n",
      "Epoch: 960/1000............. Loss: 0.0503\n",
      "Epoch: 960/1000............. Bleu: 8.4895\n",
      "Epoch: 970/1000............. Loss: 0.0488\n",
      "Epoch: 970/1000............. Bleu: 8.4895\n",
      "Epoch: 980/1000............. Loss: 0.0508\n",
      "Epoch: 980/1000............. Bleu: 8.4895\n",
      "Epoch: 990/1000............. Loss: 0.0500\n",
      "Epoch: 990/1000............. Bleu: 8.4895\n",
      "Epoch: 1000/1000............. Loss: 0.0507\n",
      "Epoch: 1000/1000............. Bleu: 7.4895\n"
     ]
    }
   ],
   "source": [
    "lr = 0.002\n",
    "encoder = TransformerEncoder(len(input_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input,\n",
    "                             ffn_num_hiddens, num_heads,num_layers, dropout).to(device)\n",
    "decoder = TransformerDecoder(len(target_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input,\n",
    "                             ffn_num_hiddens, num_heads,num_layers, dropout).to(device)\n",
    "model = EncoderDecoder(encoder, decoder).to(device)\n",
    "optimizer_002 = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler_002 = torch.optim.lr_scheduler.MultiStepLR(optimizer_002, milestones=[num_epochs//5, num_epochs*2//5,\n",
    "                                                                        num_epochs*3//5, num_epochs*4//5], gamma=0.6)\n",
    "training_results['transformer_ln_'+str(lr)] = train_transformer(model, num_epochs, data_iter, optimizer_002, scheduler_002)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('transformer_weights_'+str(corpus_size)+'_sentences_' + str(num_epochs)+'_epochs.pth'))\n",
    "# model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "([0.6817418374412535,\n  0.45834389611798343,\n  0.38528641704977806,\n  0.33479146689296246,\n  0.2908873040992093,\n  0.2625704732865467,\n  0.23629081982483802,\n  0.21643181064874217,\n  0.19900040434017113,\n  0.18440526697404339,\n  0.17146390448461196,\n  0.1621798811843798,\n  0.154307994145063,\n  0.14562324519087866,\n  0.1376012440489755,\n  0.13195119199428265,\n  0.12733740716876552,\n  0.12135101952126454,\n  0.11779919166540752,\n  0.11342471640197199,\n  0.10915399388918234,\n  0.10366721144188183,\n  0.09811161970946079,\n  0.09646603703826408,\n  0.09575186983220196,\n  0.09455583040620025,\n  0.09257373031716194,\n  0.09100239757150003,\n  0.08820032544278161,\n  0.08879781258179305,\n  0.08612169359683285,\n  0.08578849458664221,\n  0.08198805466133655,\n  0.08044876021226147,\n  0.08024138372207994,\n  0.08018645260556256,\n  0.079933258827482,\n  0.07698083090192545,\n  0.07667401284955819,\n  0.07648229709867946,\n  0.07486825744235423,\n  0.0698912980767643,\n  0.06954861110573565,\n  0.06790465014451051,\n  0.06807714787630167,\n  0.06811806818466816,\n  0.06684636656463436,\n  0.06677880122882825,\n  0.0650250945477273,\n  0.06647973936472401,\n  0.06413526581397548,\n  0.06430740453203646,\n  0.0639775598107118,\n  0.06349938758909765,\n  0.06180515543297264,\n  0.061653467394841496,\n  0.061986983691731355,\n  0.06024887465543713,\n  0.06398075243253029,\n  0.06178547680390559,\n  0.06070715437175305,\n  0.059628871650832874,\n  0.05857778789880688,\n  0.05709393899805121,\n  0.05766719583476278,\n  0.05619386859636583,\n  0.056071846259872445,\n  0.05651621615954722,\n  0.05650949367280491,\n  0.05750567795635152,\n  0.05620678220534017,\n  0.05491195413431842,\n  0.056951221465258134,\n  0.05313258976393083,\n  0.057699438734907245,\n  0.05411024361729143,\n  0.05397686084464296,\n  0.053833536153312364,\n  0.05379182403925684,\n  0.053984483788618705,\n  0.053979277182421605,\n  0.05359069289628962,\n  0.05318809860832619,\n  0.05263482539100945,\n  0.053776632174707774,\n  0.05258459350418223,\n  0.051208129218405285,\n  0.053504014766082734,\n  0.05278100263893516,\n  0.05166793691005799,\n  0.052144306806146255,\n  0.05222696825606806,\n  0.05080524646966257,\n  0.04908022238522346,\n  0.048862108139073566,\n  0.04964865077955479,\n  0.05030848475496352,\n  0.04882132147815409,\n  0.050818473132159085,\n  0.05003753179124031,\n  0.05073249226668702],\n [0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  2.0,\n  3.0,\n  4.0,\n  4.0,\n  4.0,\n  4.0,\n  4.0,\n  6.489541659556953,\n  6.0,\n  7.489541659556953,\n  7.489541659556953,\n  5.0,\n  6.489541659556953,\n  7.0,\n  7.0,\n  7.0,\n  8.0,\n  6.0,\n  7.489541659556953,\n  6.489541659556953,\n  8.0,\n  8.0,\n  8.0,\n  8.489541659556952,\n  8.489541659556952,\n  7.489541659556953,\n  8.489541659556952,\n  8.489541659556952,\n  7.489541659556953,\n  8.489541659556952,\n  7.489541659556953,\n  6.489541659556953,\n  6.489541659556953,\n  9.489541659556952,\n  8.489541659556952,\n  7.489541659556953,\n  7.489541659556953,\n  8.489541659556952,\n  8.0,\n  8.490453541522507,\n  7.489541659556953,\n  8.489541659556952,\n  7.489541659556953,\n  7.489541659556953,\n  7.489541659556953,\n  8.489541659556952,\n  6.0,\n  8.490453541522507,\n  7.489541659556953,\n  8.489541659556952,\n  7.489541659556953,\n  8.489541659556952,\n  8.489541659556952,\n  7.489541659556953,\n  8.489541659556952,\n  8.489541659556952,\n  8.489541659556952,\n  7.489541659556953,\n  8.490453541522507,\n  7.489541659556953,\n  8.489541659556952,\n  8.489541659556952,\n  8.489541659556952,\n  8.489541659556952,\n  9.489541659556952,\n  9.489541659556952,\n  8.489541659556952,\n  8.489541659556952,\n  8.489541659556952,\n  7.489541659556953,\n  8.489541659556952,\n  7.489541659556953,\n  8.489541659556952,\n  7.489541659556953,\n  8.489541659556952,\n  8.489541659556952,\n  8.489541659556952,\n  8.489541659556952,\n  7.489541659556953,\n  8.489541659556952,\n  6.489541659556953,\n  7.489541659556953,\n  6.489541659556953,\n  6.489541659556953,\n  6.489541659556953,\n  6.489541659556953,\n  7.489541659556953,\n  7.489541659556953,\n  8.489541659556952,\n  8.489541659556952,\n  8.489541659556952,\n  8.489541659556952,\n  7.489541659556953])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results['transformer_ln_0.002']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/1000............. Loss: 0.4344\n",
      "Epoch: 10/1000............. Bleu: 0.0000\n",
      "Epoch: 20/1000............. Loss: 0.3707\n",
      "Epoch: 20/1000............. Bleu: 0.0000\n",
      "Epoch: 30/1000............. Loss: 0.3354\n",
      "Epoch: 30/1000............. Bleu: 0.0000\n",
      "Epoch: 40/1000............. Loss: 0.3147\n",
      "Epoch: 40/1000............. Bleu: 0.0000\n",
      "Epoch: 50/1000............. Loss: 0.2981\n",
      "Epoch: 50/1000............. Bleu: 0.0000\n",
      "Epoch: 60/1000............. Loss: 0.2824\n",
      "Epoch: 60/1000............. Bleu: 0.0000\n",
      "Epoch: 70/1000............. Loss: 0.2730\n",
      "Epoch: 70/1000............. Bleu: 0.0000\n",
      "Epoch: 80/1000............. Loss: 0.2634\n",
      "Epoch: 80/1000............. Bleu: 0.0000\n",
      "Epoch: 90/1000............. Loss: 0.2533\n",
      "Epoch: 90/1000............. Bleu: 0.0000\n",
      "Epoch: 100/1000............. Loss: 0.2452\n",
      "Epoch: 100/1000............. Bleu: 0.0000\n",
      "Epoch: 110/1000............. Loss: 0.2391\n",
      "Epoch: 110/1000............. Bleu: 0.0000\n",
      "Epoch: 120/1000............. Loss: 0.2350\n",
      "Epoch: 120/1000............. Bleu: 0.0000\n",
      "Epoch: 130/1000............. Loss: 0.2266\n",
      "Epoch: 130/1000............. Bleu: 0.5353\n",
      "Epoch: 140/1000............. Loss: 0.2212\n",
      "Epoch: 140/1000............. Bleu: 1.3679\n",
      "Epoch: 150/1000............. Loss: 0.2168\n",
      "Epoch: 150/1000............. Bleu: 0.0000\n",
      "Epoch: 160/1000............. Loss: 0.2157\n",
      "Epoch: 160/1000............. Bleu: 0.0000\n",
      "Epoch: 170/1000............. Loss: 0.2110\n",
      "Epoch: 170/1000............. Bleu: 0.0000\n",
      "Epoch: 180/1000............. Loss: 0.2062\n",
      "Epoch: 180/1000............. Bleu: 0.5353\n",
      "Epoch: 190/1000............. Loss: 0.2024\n",
      "Epoch: 190/1000............. Bleu: 0.5353\n",
      "Epoch: 200/1000............. Loss: 0.2002\n",
      "Epoch: 200/1000............. Bleu: 0.0000\n",
      "Epoch: 210/1000............. Loss: 0.1885\n",
      "Epoch: 210/1000............. Bleu: 0.5353\n",
      "Epoch: 220/1000............. Loss: 0.1826\n",
      "Epoch: 220/1000............. Bleu: 0.0000\n",
      "Epoch: 230/1000............. Loss: 0.1827\n",
      "Epoch: 230/1000............. Bleu: 2.0000\n",
      "Epoch: 240/1000............. Loss: 0.1791\n",
      "Epoch: 240/1000............. Bleu: 1.0000\n",
      "Epoch: 250/1000............. Loss: 0.1769\n",
      "Epoch: 250/1000............. Bleu: 1.0000\n",
      "Epoch: 260/1000............. Loss: 0.1754\n",
      "Epoch: 260/1000............. Bleu: 1.0000\n",
      "Epoch: 270/1000............. Loss: 0.1739\n",
      "Epoch: 270/1000............. Bleu: 1.0000\n",
      "Epoch: 280/1000............. Loss: 0.1707\n",
      "Epoch: 280/1000............. Bleu: 0.0000\n",
      "Epoch: 290/1000............. Loss: 0.1716\n",
      "Epoch: 290/1000............. Bleu: 1.0000\n",
      "Epoch: 300/1000............. Loss: 0.1690\n",
      "Epoch: 300/1000............. Bleu: 1.0000\n",
      "Epoch: 310/1000............. Loss: 0.1691\n",
      "Epoch: 310/1000............. Bleu: 0.0000\n",
      "Epoch: 320/1000............. Loss: 0.1665\n",
      "Epoch: 320/1000............. Bleu: 2.0000\n",
      "Epoch: 330/1000............. Loss: 0.1630\n",
      "Epoch: 330/1000............. Bleu: 0.0000\n",
      "Epoch: 340/1000............. Loss: 0.1644\n",
      "Epoch: 340/1000............. Bleu: 0.0000\n",
      "Epoch: 350/1000............. Loss: 0.1601\n",
      "Epoch: 350/1000............. Bleu: 1.0000\n",
      "Epoch: 360/1000............. Loss: 0.1591\n",
      "Epoch: 360/1000............. Bleu: 1.0000\n",
      "Epoch: 370/1000............. Loss: 0.1580\n",
      "Epoch: 370/1000............. Bleu: 1.0000\n",
      "Epoch: 380/1000............. Loss: 0.1565\n",
      "Epoch: 380/1000............. Bleu: 0.0000\n",
      "Epoch: 390/1000............. Loss: 0.1548\n",
      "Epoch: 390/1000............. Bleu: 3.0000\n",
      "Epoch: 400/1000............. Loss: 0.1542\n",
      "Epoch: 400/1000............. Bleu: 1.0000\n",
      "Epoch: 410/1000............. Loss: 0.1486\n",
      "Epoch: 410/1000............. Bleu: 3.0000\n",
      "Epoch: 420/1000............. Loss: 0.1479\n",
      "Epoch: 420/1000............. Bleu: 4.0000\n",
      "Epoch: 430/1000............. Loss: 0.1445\n",
      "Epoch: 430/1000............. Bleu: 2.0000\n",
      "Epoch: 440/1000............. Loss: 0.1436\n",
      "Epoch: 440/1000............. Bleu: 3.0000\n",
      "Epoch: 450/1000............. Loss: 0.1438\n",
      "Epoch: 450/1000............. Bleu: 3.0000\n",
      "Epoch: 460/1000............. Loss: 0.1424\n",
      "Epoch: 460/1000............. Bleu: 2.0000\n",
      "Epoch: 470/1000............. Loss: 0.1408\n",
      "Epoch: 470/1000............. Bleu: 4.0000\n",
      "Epoch: 480/1000............. Loss: 0.1407\n",
      "Epoch: 480/1000............. Bleu: 2.0000\n",
      "Epoch: 490/1000............. Loss: 0.1425\n",
      "Epoch: 490/1000............. Bleu: 2.0000\n",
      "Epoch: 500/1000............. Loss: 0.1408\n",
      "Epoch: 500/1000............. Bleu: 3.0000\n",
      "Epoch: 510/1000............. Loss: 0.1385\n",
      "Epoch: 510/1000............. Bleu: 3.0000\n",
      "Epoch: 520/1000............. Loss: 0.1372\n",
      "Epoch: 520/1000............. Bleu: 4.0000\n",
      "Epoch: 530/1000............. Loss: 0.1376\n",
      "Epoch: 530/1000............. Bleu: 3.0000\n",
      "Epoch: 540/1000............. Loss: 0.1379\n",
      "Epoch: 540/1000............. Bleu: 3.0000\n",
      "Epoch: 550/1000............. Loss: 0.1330\n",
      "Epoch: 550/1000............. Bleu: 4.0000\n",
      "Epoch: 560/1000............. Loss: 0.1340\n",
      "Epoch: 560/1000............. Bleu: 4.0000\n",
      "Epoch: 570/1000............. Loss: 0.1313\n",
      "Epoch: 570/1000............. Bleu: 4.0000\n",
      "Epoch: 580/1000............. Loss: 0.1320\n",
      "Epoch: 580/1000............. Bleu: 3.0000\n",
      "Epoch: 590/1000............. Loss: 0.1321\n",
      "Epoch: 590/1000............. Bleu: 3.0000\n",
      "Epoch: 600/1000............. Loss: 0.1316\n",
      "Epoch: 600/1000............. Bleu: 4.0000\n",
      "Epoch: 610/1000............. Loss: 0.1299\n",
      "Epoch: 610/1000............. Bleu: 5.0000\n",
      "Epoch: 620/1000............. Loss: 0.1264\n",
      "Epoch: 620/1000............. Bleu: 4.0000\n",
      "Epoch: 630/1000............. Loss: 0.1250\n",
      "Epoch: 630/1000............. Bleu: 5.0000\n",
      "Epoch: 640/1000............. Loss: 0.1280\n",
      "Epoch: 640/1000............. Bleu: 6.0000\n",
      "Epoch: 650/1000............. Loss: 0.1235\n",
      "Epoch: 650/1000............. Bleu: 7.0000\n",
      "Epoch: 660/1000............. Loss: 0.1251\n",
      "Epoch: 660/1000............. Bleu: 4.0000\n",
      "Epoch: 670/1000............. Loss: 0.1256\n",
      "Epoch: 670/1000............. Bleu: 2.0000\n",
      "Epoch: 680/1000............. Loss: 0.1247\n",
      "Epoch: 680/1000............. Bleu: 2.0000\n",
      "Epoch: 690/1000............. Loss: 0.1244\n",
      "Epoch: 690/1000............. Bleu: 3.0000\n",
      "Epoch: 700/1000............. Loss: 0.1241\n",
      "Epoch: 700/1000............. Bleu: 3.0000\n",
      "Epoch: 710/1000............. Loss: 0.1218\n",
      "Epoch: 710/1000............. Bleu: 4.0000\n",
      "Epoch: 720/1000............. Loss: 0.1213\n",
      "Epoch: 720/1000............. Bleu: 3.0000\n",
      "Epoch: 730/1000............. Loss: 0.1215\n",
      "Epoch: 730/1000............. Bleu: 4.0000\n",
      "Epoch: 740/1000............. Loss: 0.1215\n",
      "Epoch: 740/1000............. Bleu: 5.0000\n",
      "Epoch: 750/1000............. Loss: 0.1199\n",
      "Epoch: 750/1000............. Bleu: 5.0000\n",
      "Epoch: 760/1000............. Loss: 0.1209\n",
      "Epoch: 760/1000............. Bleu: 5.0000\n",
      "Epoch: 770/1000............. Loss: 0.1181\n",
      "Epoch: 770/1000............. Bleu: 3.0000\n",
      "Epoch: 780/1000............. Loss: 0.1172\n",
      "Epoch: 780/1000............. Bleu: 5.0000\n",
      "Epoch: 790/1000............. Loss: 0.1189\n",
      "Epoch: 790/1000............. Bleu: 3.0000\n",
      "Epoch: 800/1000............. Loss: 0.1187\n",
      "Epoch: 800/1000............. Bleu: 5.0000\n",
      "Epoch: 810/1000............. Loss: 0.1171\n",
      "Epoch: 810/1000............. Bleu: 4.0000\n",
      "Epoch: 820/1000............. Loss: 0.1153\n",
      "Epoch: 820/1000............. Bleu: 5.0000\n",
      "Epoch: 830/1000............. Loss: 0.1141\n",
      "Epoch: 830/1000............. Bleu: 2.0000\n",
      "Epoch: 840/1000............. Loss: 0.1147\n",
      "Epoch: 840/1000............. Bleu: 3.0000\n",
      "Epoch: 850/1000............. Loss: 0.1161\n",
      "Epoch: 850/1000............. Bleu: 2.0000\n",
      "Epoch: 860/1000............. Loss: 0.1145\n",
      "Epoch: 860/1000............. Bleu: 3.0000\n",
      "Epoch: 870/1000............. Loss: 0.1142\n",
      "Epoch: 870/1000............. Bleu: 4.0000\n",
      "Epoch: 880/1000............. Loss: 0.1125\n",
      "Epoch: 880/1000............. Bleu: 5.0000\n",
      "Epoch: 890/1000............. Loss: 0.1140\n",
      "Epoch: 890/1000............. Bleu: 5.0000\n",
      "Epoch: 900/1000............. Loss: 0.1146\n",
      "Epoch: 900/1000............. Bleu: 6.0000\n",
      "Epoch: 910/1000............. Loss: 0.1128\n",
      "Epoch: 910/1000............. Bleu: 7.0000\n",
      "Epoch: 920/1000............. Loss: 0.1117\n",
      "Epoch: 920/1000............. Bleu: 5.0000\n",
      "Epoch: 930/1000............. Loss: 0.1128\n",
      "Epoch: 930/1000............. Bleu: 4.0000\n",
      "Epoch: 940/1000............. Loss: 0.1129\n",
      "Epoch: 940/1000............. Bleu: 6.0000\n",
      "Epoch: 950/1000............. Loss: 0.1109\n",
      "Epoch: 950/1000............. Bleu: 6.0000\n",
      "Epoch: 960/1000............. Loss: 0.1100\n",
      "Epoch: 960/1000............. Bleu: 5.0000\n",
      "Epoch: 970/1000............. Loss: 0.1109\n",
      "Epoch: 970/1000............. Bleu: 6.0000\n",
      "Epoch: 980/1000............. Loss: 0.1116\n",
      "Epoch: 980/1000............. Bleu: 5.0000\n",
      "Epoch: 990/1000............. Loss: 0.1102\n",
      "Epoch: 990/1000............. Bleu: 5.0000\n",
      "Epoch: 1000/1000............. Loss: 0.1107\n",
      "Epoch: 1000/1000............. Bleu: 6.0000\n"
     ]
    }
   ],
   "source": [
    "lr = 0.002\n",
    "encoder = TransformerEncoder_no_ln(len(input_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input,\n",
    "                             ffn_num_hiddens, num_heads,num_layers, dropout).to(device)\n",
    "decoder = TransformerDecoder_no_ln(len(target_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input,\n",
    "                             ffn_num_hiddens, num_heads,num_layers, dropout).to(device)\n",
    "model = EncoderDecoder(encoder, decoder).to(device)\n",
    "optimizer_002 = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler_002 = torch.optim.lr_scheduler.MultiStepLR(optimizer_002, milestones=[num_epochs//5, num_epochs*2//5,\n",
    "                                                                                num_epochs*3//5, num_epochs*4//5], gamma=0.6)\n",
    "training_results['transformer_no_ln_'+str(lr)] = train_transformer_no_ln(model, num_epochs, data_iter, optimizer_002, scheduler_002)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/1000............. Loss: 0.5322\n",
      "Epoch: 10/1000............. Bleu: 0.0000\n",
      "Epoch: 20/1000............. Loss: 0.4955\n",
      "Epoch: 20/1000............. Bleu: 0.0000\n",
      "Epoch: 30/1000............. Loss: 0.4680\n",
      "Epoch: 30/1000............. Bleu: 0.0000\n",
      "Epoch: 40/1000............. Loss: 0.4453\n",
      "Epoch: 40/1000............. Bleu: 0.0000\n",
      "Epoch: 50/1000............. Loss: 0.4245\n",
      "Epoch: 50/1000............. Bleu: 0.0000\n",
      "Epoch: 60/1000............. Loss: 0.4071\n",
      "Epoch: 60/1000............. Bleu: 0.0000\n",
      "Epoch: 70/1000............. Loss: 0.3897\n",
      "Epoch: 70/1000............. Bleu: 0.0000\n",
      "Epoch: 80/1000............. Loss: 0.3746\n",
      "Epoch: 80/1000............. Bleu: 0.0000\n",
      "Epoch: 90/1000............. Loss: 0.3609\n",
      "Epoch: 90/1000............. Bleu: 0.0000\n",
      "Epoch: 100/1000............. Loss: 0.3470\n",
      "Epoch: 100/1000............. Bleu: 0.0000\n",
      "Epoch: 110/1000............. Loss: 0.3347\n",
      "Epoch: 110/1000............. Bleu: 0.0000\n",
      "Epoch: 120/1000............. Loss: 0.3224\n",
      "Epoch: 120/1000............. Bleu: 0.0000\n",
      "Epoch: 130/1000............. Loss: 0.3108\n",
      "Epoch: 130/1000............. Bleu: 0.0000\n",
      "Epoch: 140/1000............. Loss: 0.3002\n",
      "Epoch: 140/1000............. Bleu: 0.0000\n",
      "Epoch: 150/1000............. Loss: 0.2903\n",
      "Epoch: 150/1000............. Bleu: 0.0000\n",
      "Epoch: 160/1000............. Loss: 0.2803\n",
      "Epoch: 160/1000............. Bleu: 0.0000\n",
      "Epoch: 170/1000............. Loss: 0.2725\n",
      "Epoch: 170/1000............. Bleu: 0.0000\n",
      "Epoch: 180/1000............. Loss: 0.2631\n",
      "Epoch: 180/1000............. Bleu: 0.0000\n",
      "Epoch: 190/1000............. Loss: 0.2549\n",
      "Epoch: 190/1000............. Bleu: 1.0000\n",
      "Epoch: 200/1000............. Loss: 0.2484\n",
      "Epoch: 200/1000............. Bleu: 1.0000\n",
      "Epoch: 210/1000............. Loss: 0.2430\n",
      "Epoch: 210/1000............. Bleu: 1.0000\n",
      "Epoch: 220/1000............. Loss: 0.2378\n",
      "Epoch: 220/1000............. Bleu: 1.0000\n",
      "Epoch: 230/1000............. Loss: 0.2335\n",
      "Epoch: 230/1000............. Bleu: 1.0000\n",
      "Epoch: 240/1000............. Loss: 0.2303\n",
      "Epoch: 240/1000............. Bleu: 1.0000\n",
      "Epoch: 250/1000............. Loss: 0.2253\n",
      "Epoch: 250/1000............. Bleu: 1.0000\n",
      "Epoch: 260/1000............. Loss: 0.2229\n",
      "Epoch: 260/1000............. Bleu: 1.0000\n",
      "Epoch: 270/1000............. Loss: 0.2187\n",
      "Epoch: 270/1000............. Bleu: 1.0000\n",
      "Epoch: 280/1000............. Loss: 0.2148\n",
      "Epoch: 280/1000............. Bleu: 2.0000\n",
      "Epoch: 290/1000............. Loss: 0.2108\n",
      "Epoch: 290/1000............. Bleu: 3.0000\n",
      "Epoch: 300/1000............. Loss: 0.2070\n",
      "Epoch: 300/1000............. Bleu: 1.0000\n",
      "Epoch: 310/1000............. Loss: 0.2052\n",
      "Epoch: 310/1000............. Bleu: 3.0000\n",
      "Epoch: 320/1000............. Loss: 0.2015\n",
      "Epoch: 320/1000............. Bleu: 3.0000\n",
      "Epoch: 330/1000............. Loss: 0.1979\n",
      "Epoch: 330/1000............. Bleu: 3.0000\n",
      "Epoch: 340/1000............. Loss: 0.1946\n",
      "Epoch: 340/1000............. Bleu: 3.0000\n",
      "Epoch: 350/1000............. Loss: 0.1946\n",
      "Epoch: 350/1000............. Bleu: 3.0000\n",
      "Epoch: 360/1000............. Loss: 0.1916\n",
      "Epoch: 360/1000............. Bleu: 3.0000\n",
      "Epoch: 370/1000............. Loss: 0.1875\n",
      "Epoch: 370/1000............. Bleu: 3.0000\n",
      "Epoch: 380/1000............. Loss: 0.1868\n",
      "Epoch: 380/1000............. Bleu: 3.0000\n",
      "Epoch: 390/1000............. Loss: 0.1823\n",
      "Epoch: 390/1000............. Bleu: 3.0000\n",
      "Epoch: 400/1000............. Loss: 0.1806\n",
      "Epoch: 400/1000............. Bleu: 4.0000\n",
      "Epoch: 410/1000............. Loss: 0.1776\n",
      "Epoch: 410/1000............. Bleu: 4.0000\n",
      "Epoch: 420/1000............. Loss: 0.1766\n",
      "Epoch: 420/1000............. Bleu: 3.0000\n",
      "Epoch: 430/1000............. Loss: 0.1739\n",
      "Epoch: 430/1000............. Bleu: 4.0000\n",
      "Epoch: 440/1000............. Loss: 0.1743\n",
      "Epoch: 440/1000............. Bleu: 4.0000\n",
      "Epoch: 450/1000............. Loss: 0.1730\n",
      "Epoch: 450/1000............. Bleu: 4.0000\n",
      "Epoch: 460/1000............. Loss: 0.1725\n",
      "Epoch: 460/1000............. Bleu: 4.0000\n",
      "Epoch: 470/1000............. Loss: 0.1690\n",
      "Epoch: 470/1000............. Bleu: 4.0000\n",
      "Epoch: 480/1000............. Loss: 0.1684\n",
      "Epoch: 480/1000............. Bleu: 5.0000\n",
      "Epoch: 490/1000............. Loss: 0.1683\n",
      "Epoch: 490/1000............. Bleu: 5.0000\n",
      "Epoch: 500/1000............. Loss: 0.1669\n",
      "Epoch: 500/1000............. Bleu: 4.0000\n",
      "Epoch: 510/1000............. Loss: 0.1648\n",
      "Epoch: 510/1000............. Bleu: 4.0000\n",
      "Epoch: 520/1000............. Loss: 0.1641\n",
      "Epoch: 520/1000............. Bleu: 4.0000\n",
      "Epoch: 530/1000............. Loss: 0.1639\n",
      "Epoch: 530/1000............. Bleu: 4.0000\n",
      "Epoch: 540/1000............. Loss: 0.1616\n",
      "Epoch: 540/1000............. Bleu: 4.0000\n",
      "Epoch: 550/1000............. Loss: 0.1609\n",
      "Epoch: 550/1000............. Bleu: 4.0000\n",
      "Epoch: 560/1000............. Loss: 0.1588\n",
      "Epoch: 560/1000............. Bleu: 4.0000\n",
      "Epoch: 570/1000............. Loss: 0.1582\n",
      "Epoch: 570/1000............. Bleu: 5.0000\n",
      "Epoch: 580/1000............. Loss: 0.1583\n",
      "Epoch: 580/1000............. Bleu: 5.0000\n",
      "Epoch: 590/1000............. Loss: 0.1560\n",
      "Epoch: 590/1000............. Bleu: 5.0000\n",
      "Epoch: 600/1000............. Loss: 0.1551\n",
      "Epoch: 600/1000............. Bleu: 5.0000\n",
      "Epoch: 610/1000............. Loss: 0.1538\n",
      "Epoch: 610/1000............. Bleu: 5.0000\n",
      "Epoch: 620/1000............. Loss: 0.1551\n",
      "Epoch: 620/1000............. Bleu: 5.0000\n",
      "Epoch: 630/1000............. Loss: 0.1519\n",
      "Epoch: 630/1000............. Bleu: 4.0000\n",
      "Epoch: 640/1000............. Loss: 0.1528\n",
      "Epoch: 640/1000............. Bleu: 5.0000\n",
      "Epoch: 650/1000............. Loss: 0.1518\n",
      "Epoch: 650/1000............. Bleu: 5.0000\n",
      "Epoch: 660/1000............. Loss: 0.1510\n",
      "Epoch: 660/1000............. Bleu: 5.0000\n",
      "Epoch: 670/1000............. Loss: 0.1504\n",
      "Epoch: 670/1000............. Bleu: 5.0000\n",
      "Epoch: 680/1000............. Loss: 0.1505\n",
      "Epoch: 680/1000............. Bleu: 5.0000\n",
      "Epoch: 690/1000............. Loss: 0.1502\n",
      "Epoch: 690/1000............. Bleu: 5.0000\n",
      "Epoch: 700/1000............. Loss: 0.1494\n",
      "Epoch: 700/1000............. Bleu: 5.0000\n",
      "Epoch: 710/1000............. Loss: 0.1490\n",
      "Epoch: 710/1000............. Bleu: 5.0000\n",
      "Epoch: 720/1000............. Loss: 0.1478\n",
      "Epoch: 720/1000............. Bleu: 5.0000\n",
      "Epoch: 730/1000............. Loss: 0.1449\n",
      "Epoch: 730/1000............. Bleu: 5.0000\n",
      "Epoch: 740/1000............. Loss: 0.1461\n",
      "Epoch: 740/1000............. Bleu: 5.0000\n",
      "Epoch: 750/1000............. Loss: 0.1472\n",
      "Epoch: 750/1000............. Bleu: 5.0000\n",
      "Epoch: 760/1000............. Loss: 0.1461\n",
      "Epoch: 760/1000............. Bleu: 5.0000\n",
      "Epoch: 770/1000............. Loss: 0.1446\n",
      "Epoch: 770/1000............. Bleu: 5.0000\n",
      "Epoch: 780/1000............. Loss: 0.1432\n",
      "Epoch: 780/1000............. Bleu: 5.0000\n",
      "Epoch: 790/1000............. Loss: 0.1435\n",
      "Epoch: 790/1000............. Bleu: 5.0000\n",
      "Epoch: 800/1000............. Loss: 0.1418\n",
      "Epoch: 800/1000............. Bleu: 5.0000\n",
      "Epoch: 810/1000............. Loss: 0.1406\n",
      "Epoch: 810/1000............. Bleu: 5.0000\n",
      "Epoch: 820/1000............. Loss: 0.1421\n",
      "Epoch: 820/1000............. Bleu: 5.0000\n",
      "Epoch: 830/1000............. Loss: 0.1401\n",
      "Epoch: 830/1000............. Bleu: 5.0000\n",
      "Epoch: 840/1000............. Loss: 0.1387\n",
      "Epoch: 840/1000............. Bleu: 5.0000\n",
      "Epoch: 850/1000............. Loss: 0.1399\n",
      "Epoch: 850/1000............. Bleu: 5.0000\n",
      "Epoch: 860/1000............. Loss: 0.1396\n",
      "Epoch: 860/1000............. Bleu: 5.0000\n",
      "Epoch: 870/1000............. Loss: 0.1408\n",
      "Epoch: 870/1000............. Bleu: 5.0000\n",
      "Epoch: 880/1000............. Loss: 0.1410\n",
      "Epoch: 880/1000............. Bleu: 5.0000\n",
      "Epoch: 890/1000............. Loss: 0.1383\n",
      "Epoch: 890/1000............. Bleu: 5.0000\n",
      "Epoch: 900/1000............. Loss: 0.1380\n",
      "Epoch: 900/1000............. Bleu: 5.0000\n",
      "Epoch: 910/1000............. Loss: 0.1398\n",
      "Epoch: 910/1000............. Bleu: 5.0000\n",
      "Epoch: 920/1000............. Loss: 0.1396\n",
      "Epoch: 920/1000............. Bleu: 5.0000\n",
      "Epoch: 930/1000............. Loss: 0.1377\n",
      "Epoch: 930/1000............. Bleu: 5.0000\n",
      "Epoch: 940/1000............. Loss: 0.1370\n",
      "Epoch: 940/1000............. Bleu: 6.0000\n",
      "Epoch: 950/1000............. Loss: 0.1375\n",
      "Epoch: 950/1000............. Bleu: 6.0000\n",
      "Epoch: 960/1000............. Loss: 0.1360\n",
      "Epoch: 960/1000............. Bleu: 5.0000\n",
      "Epoch: 970/1000............. Loss: 0.1365\n",
      "Epoch: 970/1000............. Bleu: 5.0000\n",
      "Epoch: 980/1000............. Loss: 0.1353\n",
      "Epoch: 980/1000............. Bleu: 6.0000\n",
      "Epoch: 990/1000............. Loss: 0.1366\n",
      "Epoch: 990/1000............. Bleu: 6.0000\n",
      "Epoch: 1000/1000............. Loss: 0.1370\n",
      "Epoch: 1000/1000............. Bleu: 5.0000\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0005\n",
    "encoder = TransformerEncoder(len(input_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input,\n",
    "                             ffn_num_hiddens, num_heads,num_layers, dropout).to(device)\n",
    "decoder = TransformerDecoder(len(target_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input,\n",
    "                             ffn_num_hiddens, num_heads,num_layers, dropout).to(device)\n",
    "model = EncoderDecoder(encoder, decoder).to(device)\n",
    "optimizer_002 = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler_002 = torch.optim.lr_scheduler.MultiStepLR(optimizer_002, milestones=[num_epochs//5, num_epochs*2//5,\n",
    "                                                                                num_epochs*3//5, num_epochs*4//5], gamma=0.6)\n",
    "training_results['transformer_ln_'+str(lr)] = train_transformer(model, num_epochs, data_iter, optimizer_002, scheduler_002)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/1000............. Loss: 0.5803\n",
      "Epoch: 10/1000............. Bleu: 0.0000\n",
      "Epoch: 20/1000............. Loss: 0.4855\n",
      "Epoch: 20/1000............. Bleu: 0.0000\n",
      "Epoch: 30/1000............. Loss: 0.4443\n",
      "Epoch: 30/1000............. Bleu: 0.0000\n",
      "Epoch: 40/1000............. Loss: 0.4167\n",
      "Epoch: 40/1000............. Bleu: 0.0000\n",
      "Epoch: 50/1000............. Loss: 0.3941\n",
      "Epoch: 50/1000............. Bleu: 0.0000\n",
      "Epoch: 60/1000............. Loss: 0.3760\n",
      "Epoch: 60/1000............. Bleu: 0.0000\n",
      "Epoch: 70/1000............. Loss: 0.3632\n",
      "Epoch: 70/1000............. Bleu: 0.0000\n",
      "Epoch: 80/1000............. Loss: 0.3502\n",
      "Epoch: 80/1000............. Bleu: 0.0000\n",
      "Epoch: 90/1000............. Loss: 0.3392\n",
      "Epoch: 90/1000............. Bleu: 0.0000\n",
      "Epoch: 100/1000............. Loss: 0.3293\n",
      "Epoch: 100/1000............. Bleu: 0.0000\n",
      "Epoch: 110/1000............. Loss: 0.3224\n",
      "Epoch: 110/1000............. Bleu: 0.0000\n",
      "Epoch: 120/1000............. Loss: 0.3133\n",
      "Epoch: 120/1000............. Bleu: 0.0000\n",
      "Epoch: 130/1000............. Loss: 0.3052\n",
      "Epoch: 130/1000............. Bleu: 0.0000\n",
      "Epoch: 140/1000............. Loss: 0.2997\n",
      "Epoch: 140/1000............. Bleu: 0.0000\n",
      "Epoch: 150/1000............. Loss: 0.2932\n",
      "Epoch: 150/1000............. Bleu: 0.0000\n",
      "Epoch: 160/1000............. Loss: 0.2849\n",
      "Epoch: 160/1000............. Bleu: 0.0000\n",
      "Epoch: 170/1000............. Loss: 0.2827\n",
      "Epoch: 170/1000............. Bleu: 0.0000\n",
      "Epoch: 180/1000............. Loss: 0.2766\n",
      "Epoch: 180/1000............. Bleu: 0.0000\n",
      "Epoch: 190/1000............. Loss: 0.2721\n",
      "Epoch: 190/1000............. Bleu: 0.0000\n",
      "Epoch: 200/1000............. Loss: 0.2667\n",
      "Epoch: 200/1000............. Bleu: 0.5353\n",
      "Epoch: 210/1000............. Loss: 0.2598\n",
      "Epoch: 210/1000............. Bleu: 0.0000\n",
      "Epoch: 220/1000............. Loss: 0.2580\n",
      "Epoch: 220/1000............. Bleu: 0.0000\n",
      "Epoch: 230/1000............. Loss: 0.2561\n",
      "Epoch: 230/1000............. Bleu: 0.0000\n",
      "Epoch: 240/1000............. Loss: 0.2521\n",
      "Epoch: 240/1000............. Bleu: 0.0000\n",
      "Epoch: 250/1000............. Loss: 0.2507\n",
      "Epoch: 250/1000............. Bleu: 0.0000\n",
      "Epoch: 260/1000............. Loss: 0.2471\n",
      "Epoch: 260/1000............. Bleu: 0.0000\n",
      "Epoch: 270/1000............. Loss: 0.2468\n",
      "Epoch: 270/1000............. Bleu: 0.0000\n",
      "Epoch: 280/1000............. Loss: 0.2416\n",
      "Epoch: 280/1000............. Bleu: 0.0000\n",
      "Epoch: 290/1000............. Loss: 0.2425\n",
      "Epoch: 290/1000............. Bleu: 0.0000\n",
      "Epoch: 300/1000............. Loss: 0.2396\n",
      "Epoch: 300/1000............. Bleu: 0.0000\n",
      "Epoch: 310/1000............. Loss: 0.2365\n",
      "Epoch: 310/1000............. Bleu: 0.0000\n",
      "Epoch: 320/1000............. Loss: 0.2339\n",
      "Epoch: 320/1000............. Bleu: 0.0000\n",
      "Epoch: 330/1000............. Loss: 0.2328\n",
      "Epoch: 330/1000............. Bleu: 0.0000\n",
      "Epoch: 340/1000............. Loss: 0.2288\n",
      "Epoch: 340/1000............. Bleu: 0.0000\n",
      "Epoch: 350/1000............. Loss: 0.2293\n",
      "Epoch: 350/1000............. Bleu: 0.0000\n",
      "Epoch: 360/1000............. Loss: 0.2277\n",
      "Epoch: 360/1000............. Bleu: 0.0000\n",
      "Epoch: 370/1000............. Loss: 0.2236\n",
      "Epoch: 370/1000............. Bleu: 0.0000\n",
      "Epoch: 380/1000............. Loss: 0.2229\n",
      "Epoch: 380/1000............. Bleu: 0.0000\n",
      "Epoch: 390/1000............. Loss: 0.2205\n",
      "Epoch: 390/1000............. Bleu: 0.0000\n",
      "Epoch: 400/1000............. Loss: 0.2195\n",
      "Epoch: 400/1000............. Bleu: 0.0000\n",
      "Epoch: 410/1000............. Loss: 0.2169\n",
      "Epoch: 410/1000............. Bleu: 0.0000\n",
      "Epoch: 420/1000............. Loss: 0.2137\n",
      "Epoch: 420/1000............. Bleu: 0.0000\n",
      "Epoch: 430/1000............. Loss: 0.2152\n",
      "Epoch: 430/1000............. Bleu: 0.0000\n",
      "Epoch: 440/1000............. Loss: 0.2116\n",
      "Epoch: 440/1000............. Bleu: 0.0000\n",
      "Epoch: 450/1000............. Loss: 0.2130\n",
      "Epoch: 450/1000............. Bleu: 0.0000\n",
      "Epoch: 460/1000............. Loss: 0.2104\n",
      "Epoch: 460/1000............. Bleu: 0.0000\n",
      "Epoch: 470/1000............. Loss: 0.2098\n",
      "Epoch: 470/1000............. Bleu: 0.0000\n",
      "Epoch: 480/1000............. Loss: 0.2080\n",
      "Epoch: 480/1000............. Bleu: 0.0000\n",
      "Epoch: 490/1000............. Loss: 0.2045\n",
      "Epoch: 490/1000............. Bleu: 0.0000\n",
      "Epoch: 500/1000............. Loss: 0.2080\n",
      "Epoch: 500/1000............. Bleu: 0.0000\n",
      "Epoch: 510/1000............. Loss: 0.2041\n",
      "Epoch: 510/1000............. Bleu: 0.0000\n",
      "Epoch: 520/1000............. Loss: 0.2033\n",
      "Epoch: 520/1000............. Bleu: 0.0000\n",
      "Epoch: 530/1000............. Loss: 0.2002\n",
      "Epoch: 530/1000............. Bleu: 0.0000\n",
      "Epoch: 540/1000............. Loss: 0.2033\n",
      "Epoch: 540/1000............. Bleu: 0.0000\n",
      "Epoch: 550/1000............. Loss: 0.1997\n",
      "Epoch: 550/1000............. Bleu: 0.0000\n",
      "Epoch: 560/1000............. Loss: 0.1999\n",
      "Epoch: 560/1000............. Bleu: 0.0000\n",
      "Epoch: 570/1000............. Loss: 0.1984\n",
      "Epoch: 570/1000............. Bleu: 0.0000\n",
      "Epoch: 580/1000............. Loss: 0.1979\n",
      "Epoch: 580/1000............. Bleu: 0.0000\n",
      "Epoch: 590/1000............. Loss: 0.1955\n",
      "Epoch: 590/1000............. Bleu: 0.0000\n",
      "Epoch: 600/1000............. Loss: 0.1951\n",
      "Epoch: 600/1000............. Bleu: 0.0000\n",
      "Epoch: 610/1000............. Loss: 0.1950\n",
      "Epoch: 610/1000............. Bleu: 0.0000\n",
      "Epoch: 620/1000............. Loss: 0.1933\n",
      "Epoch: 620/1000............. Bleu: 0.0000\n",
      "Epoch: 630/1000............. Loss: 0.1915\n",
      "Epoch: 630/1000............. Bleu: 0.0000\n",
      "Epoch: 640/1000............. Loss: 0.1924\n",
      "Epoch: 640/1000............. Bleu: 0.0000\n",
      "Epoch: 650/1000............. Loss: 0.1911\n",
      "Epoch: 650/1000............. Bleu: 1.0000\n",
      "Epoch: 660/1000............. Loss: 0.1916\n",
      "Epoch: 660/1000............. Bleu: 1.0000\n",
      "Epoch: 670/1000............. Loss: 0.1896\n",
      "Epoch: 670/1000............. Bleu: 1.0000\n",
      "Epoch: 680/1000............. Loss: 0.1907\n",
      "Epoch: 680/1000............. Bleu: 1.0000\n",
      "Epoch: 690/1000............. Loss: 0.1877\n",
      "Epoch: 690/1000............. Bleu: 1.0000\n",
      "Epoch: 700/1000............. Loss: 0.1903\n",
      "Epoch: 700/1000............. Bleu: 1.0000\n",
      "Epoch: 710/1000............. Loss: 0.1864\n",
      "Epoch: 710/1000............. Bleu: 1.0000\n",
      "Epoch: 720/1000............. Loss: 0.1864\n",
      "Epoch: 720/1000............. Bleu: 1.0000\n",
      "Epoch: 730/1000............. Loss: 0.1847\n",
      "Epoch: 730/1000............. Bleu: 1.0000\n",
      "Epoch: 740/1000............. Loss: 0.1849\n",
      "Epoch: 740/1000............. Bleu: 1.0000\n",
      "Epoch: 750/1000............. Loss: 0.1836\n",
      "Epoch: 750/1000............. Bleu: 1.0000\n",
      "Epoch: 760/1000............. Loss: 0.1848\n",
      "Epoch: 760/1000............. Bleu: 1.0000\n",
      "Epoch: 770/1000............. Loss: 0.1827\n",
      "Epoch: 770/1000............. Bleu: 2.0000\n",
      "Epoch: 780/1000............. Loss: 0.1841\n",
      "Epoch: 780/1000............. Bleu: 1.0000\n",
      "Epoch: 790/1000............. Loss: 0.1816\n",
      "Epoch: 790/1000............. Bleu: 2.0000\n",
      "Epoch: 800/1000............. Loss: 0.1824\n",
      "Epoch: 800/1000............. Bleu: 2.0000\n",
      "Epoch: 810/1000............. Loss: 0.1811\n",
      "Epoch: 810/1000............. Bleu: 2.0000\n",
      "Epoch: 820/1000............. Loss: 0.1810\n",
      "Epoch: 820/1000............. Bleu: 2.0000\n",
      "Epoch: 830/1000............. Loss: 0.1801\n",
      "Epoch: 830/1000............. Bleu: 2.0000\n",
      "Epoch: 840/1000............. Loss: 0.1803\n",
      "Epoch: 840/1000............. Bleu: 2.0000\n",
      "Epoch: 850/1000............. Loss: 0.1796\n",
      "Epoch: 850/1000............. Bleu: 2.0000\n",
      "Epoch: 860/1000............. Loss: 0.1800\n",
      "Epoch: 860/1000............. Bleu: 1.0000\n",
      "Epoch: 870/1000............. Loss: 0.1785\n",
      "Epoch: 870/1000............. Bleu: 1.0000\n",
      "Epoch: 880/1000............. Loss: 0.1775\n",
      "Epoch: 880/1000............. Bleu: 1.0000\n",
      "Epoch: 890/1000............. Loss: 0.1772\n",
      "Epoch: 890/1000............. Bleu: 1.0000\n",
      "Epoch: 900/1000............. Loss: 0.1775\n",
      "Epoch: 900/1000............. Bleu: 1.0000\n",
      "Epoch: 910/1000............. Loss: 0.1781\n",
      "Epoch: 910/1000............. Bleu: 1.0000\n",
      "Epoch: 920/1000............. Loss: 0.1776\n",
      "Epoch: 920/1000............. Bleu: 2.0000\n",
      "Epoch: 930/1000............. Loss: 0.1781\n",
      "Epoch: 930/1000............. Bleu: 2.0000\n",
      "Epoch: 940/1000............. Loss: 0.1774\n",
      "Epoch: 940/1000............. Bleu: 2.0000\n",
      "Epoch: 950/1000............. Loss: 0.1764\n",
      "Epoch: 950/1000............. Bleu: 2.0000\n",
      "Epoch: 960/1000............. Loss: 0.1768\n",
      "Epoch: 960/1000............. Bleu: 2.0000\n",
      "Epoch: 970/1000............. Loss: 0.1738\n",
      "Epoch: 970/1000............. Bleu: 2.0000\n",
      "Epoch: 980/1000............. Loss: 0.1709\n",
      "Epoch: 980/1000............. Bleu: 1.0000\n",
      "Epoch: 990/1000............. Loss: 0.1755\n",
      "Epoch: 990/1000............. Bleu: 2.0000\n",
      "Epoch: 1000/1000............. Loss: 0.1746\n",
      "Epoch: 1000/1000............. Bleu: 2.0000\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0005\n",
    "encoder = TransformerEncoder_no_ln(len(input_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input,\n",
    "                                   ffn_num_hiddens, num_heads,num_layers, dropout).to(device)\n",
    "decoder = TransformerDecoder_no_ln(len(target_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input,\n",
    "                                   ffn_num_hiddens, num_heads,num_layers, dropout).to(device)\n",
    "model = EncoderDecoder(encoder, decoder).to(device)\n",
    "optimizer_002 = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler_002 = torch.optim.lr_scheduler.MultiStepLR(optimizer_002, milestones=[num_epochs//5, num_epochs*2//5,\n",
    "                                                                                num_epochs*3//5, num_epochs*4//5], gamma=0.6)\n",
    "training_results['transformer_no_ln_'+str(lr)] = train_transformer_no_ln(model, num_epochs, data_iter, optimizer_002, scheduler_002)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x396 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in training_results:\n",
    "    curr_result = training_results[key]\n",
    "\n",
    "    plt.plot(curr_result[1], label = key)\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('Transformer_performance.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "translation, dec_attention_weight_seq = predict_seq2seq(model, \"when you think about it\", input_vocab, target_vocab\n",
    "                                                        , 5, device, True)\n",
    "print(translation)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
