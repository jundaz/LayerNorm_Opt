{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.style as style\n",
    "style.use('seaborn')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device_id = 0\n",
    "num_workers = 4\n",
    "\n",
    "batch_size = 128\n",
    "default_learning_rate = 0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import PIL.Image as Image\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms, utils\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from tqdm import tqdm as tqdm\n",
    "from IPython import display"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# add our package dir to path\n",
    "module_path = os.path.dirname(os.getcwd())\n",
    "sys.path.append(module_path)\n",
    "\n",
    "home_path = module_path\n",
    "figures_path = os.path.join(home_path, 'reports', 'figures')\n",
    "models_path = os.path.join(home_path, 'reports', 'models')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device_id = device_id\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(device_id)\n",
    "\n",
    "device = torch.device(\"cuda:{}\".format(device_id) if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(device_id))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PartialDataset(Dataset):\n",
    "    def __init__(self, dataset, n_items=10):\n",
    "        self.dataset = dataset\n",
    "        self.n_items = n_items\n",
    "\n",
    "    def __getitem__(self):\n",
    "        return self.dataset.__getitem__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(self.n_items, len(self.dataset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                 std=[0.5, 0.5, 0.5])\n",
    "train_transform = transforms.Compose(\n",
    "    [#transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomCrop(32, 4),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize\n",
    "     ])\n",
    "\n",
    "dataset_train = datasets.CIFAR10(root='../data/', train=True, download=True, transform=train_transform)\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "dataset_val = datasets.CIFAR10(root='../data/', train=False, download=True, transform=val_transform)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "\n",
    "n_items = 10\n",
    "dataset_train_part = PartialDataset(dataset_train, n_items)\n",
    "train_loader_part = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for X,y in train_loader:\n",
    "    print(X[0])\n",
    "    print(y[0])\n",
    "    print(X[0].shape)\n",
    "    plt.imshow(np.array(X[0,0,:,:]))\n",
    "    print(X[0].max())\n",
    "    print(X[0].min())\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_number_of_parameters(model):\n",
    "    parameters_n = 0\n",
    "    for parameter in model.parameters():\n",
    "        parameters_n += np.prod(parameter.shape).item()\n",
    "\n",
    "    return parameters_n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class VGG_A(nn.Module):\n",
    "    def __init__(self, inp_ch=3, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inp_ch, out_channels=64, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage6 = nn.Sequential(\n",
    "            nn.Linear(512*1*1, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x.view(-1, 512*1*1))\n",
    "        return x\n",
    "\n",
    "class VGG_A_Batch(nn.Module):\n",
    "    def __init__(self, inp_ch=3, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inp_ch, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage6 = nn.Sequential(\n",
    "            nn.Linear(512*1*1, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x.view(-1, 512*1*1))\n",
    "        return x\n",
    "\n",
    "class VGG_A_Light(nn.Module):\n",
    "    def __init__(self, inp_ch=3, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inp_ch, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        '''\n",
    "        self.stage3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        '''\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32*8*8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        #x = self.stage3(x)\n",
    "        #x = self.stage4(x)\n",
    "        #x = self.stage5(x)\n",
    "        x = self.classifier(x.view(-1, 32*8*8))\n",
    "        return x\n",
    "\n",
    "\n",
    "class VGG_A_Dropout(nn.Module):\n",
    "    def __init__(self, inp_ch=3, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inp_ch, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.stage5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512*1*1, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.classifier(x.view(-1, 512*1*1))\n",
    "        return x\n",
    "\n",
    "print(get_number_of_parameters(VGG_A()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_accuracy(model, dataloader, device='cpu'):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)  ## <---\n",
    "            y = y.to(device)  ## <---\n",
    "            prediction = model(x).argmax(dim=-1, keepdim=True)\n",
    "            correct += prediction.eq(y.view_as(prediction)).sum().item()\n",
    "    return correct / len(dataloader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_random_seeds(seed_value=0, device='cpu'):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    if device != 'cpu':\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion,\n",
    "          train_loader,\n",
    "          val_loader,\n",
    "          scheduler=None,\n",
    "          epochs_n=100,\n",
    "          best_model_path=None):\n",
    "\n",
    "    model.to(device)\n",
    "    learning_curve = [np.nan] * epochs_n\n",
    "    train_accuracy_curve = [np.nan] * epochs_n\n",
    "    val_accuracy_curve = [np.nan] * epochs_n\n",
    "    max_val_accuracy = 0\n",
    "    max_val_accuracy_epoch = 0\n",
    "\n",
    "    batches_n = len(train_loader)\n",
    "    losses_list = []\n",
    "    for epoch in tqdm(range(epochs_n), unit='epoch'):\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        model.train()\n",
    "        loss_list = []\n",
    "        learning_curve[epoch] = 0\n",
    "        for data in train_loader:\n",
    "\n",
    "            #print(data)\n",
    "\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(x)\n",
    "            loss = criterion(prediction, y)\n",
    "            #print(loss.item())\n",
    "            loss_list.append(loss.item())\n",
    "            learning_curve[epoch] += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses_list.append(loss_list)\n",
    "        display.clear_output(wait=True)\n",
    "        f, axes = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "        learning_curve[epoch] /= batches_n\n",
    "        axes[0].plot(learning_curve)\n",
    "\n",
    "        model.eval()\n",
    "        train_accuracy_curve[epoch] = get_accuracy(model, train_loader, device)\n",
    "        val_accuracy_curve[epoch] = get_accuracy(model, val_loader, device)\n",
    "\n",
    "        val_accuracy = val_accuracy_curve[epoch]\n",
    "        if val_accuracy > max_val_accuracy:\n",
    "            max_val_accuracy = val_accuracy\n",
    "            max_val_accuracy_epoch = epoch\n",
    "            if best_model_path:\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "        axes[1].set_title('Train {:.4f}, val {:.4f}, max val {:.4f} at {}'.format(\n",
    "            train_accuracy_curve[epoch], val_accuracy, max_val_accuracy, max_val_accuracy_epoch))\n",
    "        axes[1].plot(train_accuracy_curve)\n",
    "        axes[1].plot(val_accuracy_curve)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return losses_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epo = 20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.path.join(os.getcwd(), 'best_vgg_1.pt') #change dump name here\n",
    "\n",
    "set_random_seeds(seed_value=1984, device=device)\n",
    "model = VGG_A()\n",
    "lr = 0.001\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_01 = train(model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                epochs_n=epo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_random_seeds(seed_value=1984, device=device)\n",
    "model = VGG_A()\n",
    "lr = 0.0005\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = lr, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "loss_005 = train(model,\n",
    "                 optimizer,\n",
    "                 criterion,\n",
    "                 train_loader,\n",
    "                 val_loader,\n",
    "                 epochs_n=epo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_random_seeds(seed_value=1984, device=device)\n",
    "model = VGG_A()\n",
    "lr = 0.002\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "loss_02 = train(model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                epochs_n=epo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_random_seeds(seed_value=1984, device=device)\n",
    "model = VGG_A()\n",
    "lr = 0.0001\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "\n",
    "loss_001 = train(model,\n",
    "                 optimizer,\n",
    "                 criterion,\n",
    "                 train_loader,\n",
    "                 val_loader,\n",
    "                 epochs_n=epo)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_random_seeds(seed_value=1984, device=device)\n",
    "model = VGG_A()\n",
    "lr = 0.003\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_03 = train(model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                epochs_n=epo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#import itertools\n",
    "loss_01 = np.array(loss_01).flatten()\n",
    "loss_02 = np.array(loss_02).flatten()\n",
    "loss_005 = np.array(loss_005).flatten()\n",
    "loss_001 = np.array(loss_001).flatten()\n",
    "min_curve = []\n",
    "max_curve = []\n",
    "for i in range(len(loss_01)):\n",
    "    min_curve.append(np.min([loss_01[i], loss_02[i], loss_005[i], loss_001[i]]))\n",
    "    max_curve.append(np.max([loss_01[i], loss_02[i], loss_005[i], loss_001[i]]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.fill_between(range(len(min_curve)), min_curve, max_curve)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.fill_between(range(len(min_curve)), min_curve, max_curve)\n",
    "os.path.join(os.getcwd(), 'best_vgg_1.pt')  #change dump name here\n",
    "\n",
    "set_random_seeds(seed_value=1984, device=device)\n",
    "model = VGG_A_Batch()\n",
    "lr = 0.001\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_batch_01 = train(model,\n",
    "                      optimizer,\n",
    "                      criterion,\n",
    "                      train_loader,\n",
    "                      val_loader,\n",
    "                      epochs_n=epo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_random_seeds(seed_value=1984, device=device)\n",
    "model = VGG_A_Batch()\n",
    "lr = 0.0005\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = lr, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "loss_batch_005 = train(model,\n",
    "                       optimizer,\n",
    "                       criterion,\n",
    "                       train_loader,\n",
    "                       val_loader,\n",
    "                       epochs_n=epo)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_random_seeds(seed_value=1984, device=device)\n",
    "model = VGG_A_Batch()\n",
    "lr = 0.002\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "loss_batch_02 = train(model,\n",
    "                      optimizer,\n",
    "                      criterion,\n",
    "                      train_loader,\n",
    "                      val_loader,\n",
    "                      epochs_n=epo)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_random_seeds(seed_value=1984, device=device)\n",
    "model = VGG_A_Batch()\n",
    "lr = 0.0001\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "loss_batch_001 = train(model,\n",
    "                       optimizer,\n",
    "                       criterion,\n",
    "                       train_loader,\n",
    "                       val_loader,\n",
    "                       epochs_n=epo)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_random_seeds(seed_value=1984, device=device)\n",
    "model = VGG_A_Batch()\n",
    "lr = 0.003\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "loss_batch_03 = train(model,\n",
    "                      optimizer,\n",
    "                      criterion,\n",
    "                      train_loader,\n",
    "                      val_loader,\n",
    "                      epochs_n=epo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_batch_01 = np.array(loss_batch_01).flatten()\n",
    "loss_batch_02 = np.array(loss_batch_02).flatten()\n",
    "loss_batch_005 = np.array(loss_batch_005).flatten()\n",
    "loss_batch_001 = np.array(loss_batch_001).flatten()\n",
    "min_curve_batch = []\n",
    "max_curve_batch = []\n",
    "for i in range(len(loss_01)):\n",
    "    min_curve_batch.append(np.min([loss_batch_01[i], loss_batch_02[i], loss_batch_005[i], loss_batch_001[i]]))\n",
    "    max_curve_batch.append(np.max([loss_batch_01[i], loss_batch_02[i], loss_batch_005[i], loss_batch_001[i]]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "step = 30\n",
    "steps = np.arange(0, len(min_curve), step)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.fill_between(steps, min_curve[::step], max_curve[::step],\n",
    "                 alpha=0.5, color='C1', label='Standart VGG')\n",
    "plt.plot(steps, min_curve[::step], color='C1')\n",
    "plt.plot(steps, max_curve[::step], color='C1')\n",
    "\n",
    "plt.fill_between(steps, min_curve_batch[::step], max_curve_batch[::step],\n",
    "                 alpha=0.5, color='C2', label='Standart VGG + BatchNorm')\n",
    "plt.plot(steps, min_curve_batch[::step], color='C2')\n",
    "plt.plot(steps, max_curve_batch[::step], color='C2')\n",
    "\n",
    "plt.legend(fontsize=19)\n",
    "plt.title('Loss Landscape', fontsize=20)\n",
    "plt.ylabel('Loss Landscape', fontsize=13)\n",
    "plt.xlabel('Steps', fontsize=13)\n",
    "plt.savefig(os.path.join(figures_path, 'loss_landscape.png'), dpi=500, quality=100)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
